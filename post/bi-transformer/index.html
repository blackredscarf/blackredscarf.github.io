<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
<title>Transformer双向编码器 - 绯色的魔法世界</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">




<meta name="description" content="">





    <meta name="description" content="BERT，完整描述是使用双向编码器的Transformer (Bidirectional Encoder Representations from Transformers)， 是Google在2018年发布的一个神经网络模型 [1]。该模型与以往大多数NLP模型不同，它本身便是一个用于迁移训练的模型。 对于迁移训练，在计算机视觉中迁移训练已经是个常态了，一般都是在经过ImageNet数据训练的">
<meta name="keywords" content="机器学习,深度学习,NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformer双向编码器">
<meta property="og:url" content="http:&#x2F;&#x2F;blackredscarf.github.io&#x2F;post&#x2F;bi-transformer&#x2F;index.html">
<meta property="og:site_name" content="绯色的魔法世界">
<meta property="og:description" content="BERT，完整描述是使用双向编码器的Transformer (Bidirectional Encoder Representations from Transformers)， 是Google在2018年发布的一个神经网络模型 [1]。该模型与以往大多数NLP模型不同，它本身便是一个用于迁移训练的模型。 对于迁移训练，在计算机视觉中迁移训练已经是个常态了，一般都是在经过ImageNet数据训练的">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;03&#x2F;28&#x2F;5c9cb9bd5ce39.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;03&#x2F;28&#x2F;5c9cb9c9cccb2.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;03&#x2F;28&#x2F;5c9cb9d54ed3e.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;03&#x2F;28&#x2F;5c9cb9dcb8123.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;03&#x2F;28&#x2F;5c9cb9e51ade5.png">
<meta property="og:updated_time" content="2020-07-04T06:32:19.894Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;03&#x2F;28&#x2F;5c9cb9bd5ce39.png">





<link rel="icon" href="https://s1.ax1x.com/2020/07/25/aSC9Cn.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/highlight.js/10.1.1/styles/atom-one-light.min.css">

<link rel="stylesheet" href="/css/style.css">

<script defer src="https://cdn.bootcdn.net/ajax/libs/font-awesome/5.14.0/js/all.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


    
    
    
    
    
    
    
    
    
    

    


</head>
<body>
    

<!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="top-title-line">
        <div class="top-title">
            <a href="/"><span>绯色的魔法世界</span></a>
        </div>
    </div>
    <div class="nav-tool-line">
        <div class="nav-tool">
            
            <a class="navbar-item search" title="Search" href="javascript:;" target="_blank" rel="noopener">
                <i class="fas fa-search"></i>
            </a>
            
            
            <a class="navbar-item" title="GitHub" href="https://github.com/blackredscarf" target="_blank" rel="noopener">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>    
    </div>
    <div class="container">
        <div class="navbar-brand">
            <!-- <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a> -->
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/">Home</a>
            
            <a class="navbar-item "
               href="/archives">归档</a>
            
            <a class="navbar-item "
               href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F">操作系统</a>
            
            <a class="navbar-item "
               href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F">分布式</a>
            
            <a class="navbar-item "
               href="/categories/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1">算法设计</a>
            
            <a class="navbar-item "
               href="/categories/%E9%9A%8F%E8%AE%B0">随记</a>
            
            <a class="navbar-item "
               href="/categories/NLP">NLP</a>
            
            <a class="navbar-item "
               href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
            
        </div>
        
        
    </div>
</nav>

    <section class="section">
    <div class="container">
    
<div class="article-cover">
   <img class="article-cover-img" src="https://s2.ax1x.com/2019/11/21/MoMECD.jpg"> 
</div>

<article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            Transformer双向编码器
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            2019-03-28
            <!-- <time datetime="2019-03-27T16:00:00.000Z" itemprop="datePublished">Mar 28 2019</time> -->
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span>,</span><a class="article-category-link" href="/categories/NLP/">NLP</a><span>,</span><a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
        </span>
        
        <!--  -->
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>BERT，完整描述是使用双向编码器的Transformer (Bidirectional Encoder Representations from Transformers)， 是Google在2018年发布的一个神经网络模型 <a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">[1]</a>。该模型与以往大多数NLP模型不同，它本身便是一个用于迁移训练的模型。</p>
<p>对于迁移训练，在计算机视觉中迁移训练已经是个常态了，一般都是在经过ImageNet数据训练的预训练模型上进行微调。如今，研究人员在处理NLP问题上也希望能够通过预训练来提高模型能力。而BERT的该论文主要阐述如何在BERT模型上进行预训练，然后基于预训练模型，对于不同任务(task)进行微调。</p>
<a id="more"></a>
<h2 id="预训练与微调方法">预训练与微调方法</h2>
<p>早于BERT，OpenAI GPT提出了在transformer上进行预训练和微调的方法 <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">[2]</a>，不过与BERT不同的是，GPT采用的是单向transformer以及使用无监督数据来学习语言模型。BERT采用的方法是基于无监督数据采用有监督方法进行预训练，详细方法后面会讲到。</p>
<h2 id="模型结构">模型结构</h2>
<figure>
<img src="https://i.loli.net/2019/03/28/5c9cb9bd5ce39.png" alt="bert-1.png"><figcaption>bert-1.png</figcaption>
</figure>
<p>上图是BERT与几个相似模型的对比，只有BERT在所有层级上都加入了左右上下文的信息。</p>
<h2 id="输入表示">输入表示</h2>
<figure>
<img src="https://i.loli.net/2019/03/28/5c9cb9c9cccb2.png" alt="bert-2.png"><figcaption>bert-2.png</figcaption>
</figure>
<p>输入向量由三层组合 1. Token Embeddings 即词向量。[CLS] 表示开始标志，[SEP] 用于分割多个句子的标志 2. Segment Embeddings 段落向量。上图中的<span class="math inline">\(\large E_A, E_B\)</span> 表示两个学习过的句子A和B。为什么这么做后面会讲到。 3. Position Embeddings 位置向量。这里的位置向量不使用余弦函数，而是需要进行训练。</p>
<h2 id="预训练任务">预训练任务</h2>
<p>下面会介绍几个用于预训练的任务。</p>
<h3 id="masked-lm">Masked LM</h3>
<p>BERT 最重要的特点就是双向，能够同时掌握上下文的信息。但是这里就出现了一个问题，convS2S和transformer都在致力于使用masked去清除“过去”的影响，BERT论文中提到这么做是因为在双向多层结构中词汇会在第二层以后看到“自己”，所以要清除这种干扰。</p>
<p>而为了使得BERT这样的双向结构能够进行良好的训练，作者提出了使用Masked LM方法 <a href="https://journals.sagepub.com/doi/abs/10.1177/107769905303000401" target="_blank" rel="noopener">[3]</a>，该方法就是对于输入的句子，随机遮住(mask)掉一些词汇(token)，然后让模型去预测这个词汇。明显，token被mask掉以后就不会出现自己干扰自己的情况。mask的时候使用[MASK]标记即可。</p>
<p>但是这么做会产生一个弊端，这个[MASK]标记在微调(fine-tuning)中是不会出现的，为了减轻该影响，作者提供了方案： 1. 80% 的情况下，替换为[MASK]，比如 my dog is hairy -&gt; my dog is [MASK] 2. 10% 的情况下，替换为随机词，比如 my dog is hairy -&gt; my dog is apple 3. 10% 的情况下，不替换</p>
<h3 id="下一句预测">下一句预测</h3>
<p>就是将句子A和句子B通过[SEP]拼接起来，问你句子B是不是句子A的下一句。</p>
<p>举两个例子：</p>
<blockquote>
<p>Input = [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]</p>
<p>Label = IsNext</p>
</blockquote>
<blockquote>
<p>Input = [CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds [SEP]</p>
<p>Label = NotNext</p>
</blockquote>
<h2 id="微调">微调</h2>
<p>提取最后一层中 [CLS]标记所在隐藏状态 <span class="math inline">\(\large C \in \mathbb{R}^H\)</span>，以及你自己加上去的权重 <span class="math inline">\(\large W \in \mathbb{R}^{K \times H}\)</span>，<span class="math inline">\(\large K\)</span> 即你的分类数。通过Softmax进行预测：</p>
<p><span class="math display">\[
\large 
P = softmax(CW^T)
\]</span></p>
<p>对于超参数的调节，视不同任务而定，作者建议的参数有：</p>
<ul>
<li>Batch size: 16, 32</li>
<li>Learning rate (Adam): 5e-5, 3e-5, 2e-5</li>
<li>Number of epochs: 3, 4</li>
</ul>
<p>为了方便理解，作者提供对于不同任务的微调的图示：</p>
<figure>
<img src="https://i.loli.net/2019/03/28/5c9cb9d54ed3e.png" alt="bert-3.png"><figcaption>bert-3.png</figcaption>
</figure>
<figure>
<img src="https://i.loli.net/2019/03/28/5c9cb9dcb8123.png" alt="bert-4.png"><figcaption>bert-4.png</figcaption>
</figure>
<h2 id="实验结果">实验结果</h2>
<figure>
<img src="https://i.loli.net/2019/03/28/5c9cb9e51ade5.png" alt="bert-5.png"><figcaption>bert-5.png</figcaption>
</figure>
<p>从上图可以看出，BERT在各项任务上的表现基本是毫无敌手。(以上指标均为GLUE <a href="https://arxiv.org/abs/1804.07461" target="_blank" rel="noopener">[4]</a>)</p>
<h2 id="总结">总结</h2>
<p>BERT的实验结果表明预训练模型的优越性，尽管BERT本身有些瑕疵，但论文本身阐述了诸多预训练的方法和理论，并且表现出强劲的实力，可以说是NLP史上的一座重要的里程碑了。</p>
<p>尽管BERT能够适用于诸多任务，但也有一些任务无法胜任，比如机器翻译……</p>
<h2 id="参考文献">参考文献</h2>
<ul>
<li><a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">[1] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. 2018</a></li>
<li><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">[2] Improving Language Understandingby Generative Pre-Training. 2018</a></li>
<li><a href="https://journals.sagepub.com/doi/abs/10.1177/107769905303000401" target="_blank" rel="noopener">[3] “Cloze Procedure”: A New Tool for Measuring Readability. 1953</a></li>
<li><a href="https://arxiv.org/abs/1804.07461" target="_blank" rel="noopener">[4] GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding. 2018</a></li>
</ul>

    
    </div>
    
    <div class="columns is-variable is-1 is-multiline is-mobile">
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a></span>
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a></span>
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/NLP/">#NLP</a></span>
    
    </div>
    
    <!-- 
    <span id="post/bi-transformer/" class="leancloud_visitors" data-flag-title="Transformer双向编码器">
        <em class="post-meta-item-text">阅读量 </em>
        <i class="leancloud-visitors-count">1000000</i>
    </span>
     -->
    
    <div class="go-next columns is-mobile is-multiline article-nav">
        <span class="column is-12-mobile is-half-desktop  article-nav-prev">
            
            <a href="/post/linux-select/">Linux Select 源码分析</a>
            
        </span>
        <span class="column is-12-mobile is-half-desktop  article-nav-next">
            
            <a href="/post/transformer/">Transformer模型与自注意力</a>
            
        </span>
    </div>
    
</article>



<div class="comments">
    <h3 class="title is-4">Comments</h3>
    
<div id="valine-thread"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script>
    new Valine({
        el: '#valine-thread',
        appId: 'DEXiOMuMN86LKmdUtJYX4FRL-MdYXbMMI',
        appKey: 'tPt6E0GhkwXKEBUacbugDcWb',
        notify: true,
        verify: false,
        avatar: '',
        placeholder: 'Say something...',
        meta: ['nick', 'mail'],
        visitor: true,
        lang: ''
    })
</script>


</div>

    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2021 Black Redscarf&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" href="https://github.com/blackredscarf" target="_blank" rel="noopener">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>
</footer>
    <script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="https://cdn.bootcdn.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/" target="_blank" rel="noopener">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.bootcdn.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("en-AU");
</script>


    
    
<script src="https://cdn.bootcdn.net/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [ ['$','$'],['\\(','\\)'] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: false
        }
    });
</script>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        // ...options...
    });
});
</script>

    
    
<script src="https://cdn.bootcdn.net/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="https://cdn.bootcdn.net/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    


<script src="/js/script.js"></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</body>
</html>