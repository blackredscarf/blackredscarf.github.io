<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
<title>负采样的Skip-Gram模型 - 绯色的魔法世界</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/outdated-browser/1.1.5/outdatedbrowser.min.css">




<meta name="description" content="">





    <meta name="description" content="Word2Vec模型中，主要有Skip-Gram和CBOW两种模型，从直观上理解，Skip-Gram是给定 Input Word 来预测上下文。而CBOW是给定上下文来预测。本篇文章仅讲解Skip-Gram模型。">
<meta name="keywords" content="NLP,机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="负采样的Skip-Gram模型">
<meta property="og:url" content="http:&#x2F;&#x2F;blackredscarf.github.io&#x2F;post&#x2F;skip-gram&#x2F;index.html">
<meta property="og:site_name" content="绯色的魔法世界">
<meta property="og:description" content="Word2Vec模型中，主要有Skip-Gram和CBOW两种模型，从直观上理解，Skip-Gram是给定 Input Word 来预测上下文。而CBOW是给定上下文来预测。本篇文章仅讲解Skip-Gram模型。">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2018&#x2F;10&#x2F;08&#x2F;5bbb5e794891e.jpeg">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2018&#x2F;10&#x2F;08&#x2F;5bbb5e7907f80.png">
<meta property="og:updated_time" content="2020-07-04T06:33:55.374Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2018&#x2F;10&#x2F;08&#x2F;5bbb5e794891e.jpeg">





<link rel="icon" href="https://s1.ax1x.com/2020/07/25/aSC9Cn.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="https://lf26-cdn-tos.bytecdntp.com/cdn/expire-1-M/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/highlight.js/10.1.1/styles/atom-one-light.min.css">

<link rel="stylesheet" href="/css/style.css">

<script defer src="https://lf26-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/5.14.0/js/all.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


    
    
    
    
    
    
    
    
    
    

    


</head>
<body>
    

<!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="top-title-line">
        <div class="top-title">
            <a href="/"><span>绯色的魔法世界</span></a>
        </div>
    </div>
    <div class="nav-tool-line">
        <div class="nav-tool">
            
            <a class="navbar-item search" title="Search" href="javascript:;" target="_blank" rel="noopener">
                <i class="fas fa-search"></i>
            </a>
            
            
            <a class="navbar-item" title="GitHub" href="https://github.com/blackredscarf" target="_blank" rel="noopener">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>    
    </div>
    <div class="container">
        <div class="navbar-brand">
            <!-- <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a> -->
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/">Home</a>
            
            <a class="navbar-item "
               href="/archives">归档</a>
            
            <a class="navbar-item "
               href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F">操作系统</a>
            
            <a class="navbar-item "
               href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F">分布式</a>
            
            <a class="navbar-item "
               href="/categories/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1">算法设计</a>
            
            <a class="navbar-item "
               href="/categories/%E9%9A%8F%E8%AE%B0">随记</a>
            
            <a class="navbar-item "
               href="/categories/NLP">NLP</a>
            
            <a class="navbar-item "
               href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
            
        </div>
        
        
    </div>
</nav>

    <section class="section">
    <div class="container">
    
<div class="article-cover">
   <img class="article-cover-img" src="https://s2.ax1x.com/2019/11/21/MoMZgH.jpg"> 
</div>

<article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            负采样的Skip-Gram模型
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            2018-10-08
            <!-- <time datetime="2018-10-07T16:00:00.000Z" itemprop="datePublished">Oct 8 2018</time> -->
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/NLP/">NLP</a><span>,</span><a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
        </span>
        
        <!--  -->
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>Word2Vec模型中，主要有Skip-Gram和CBOW两种模型，从直观上理解，Skip-Gram是给定 Input Word 来预测上下文。而CBOW是给定上下文来预测。本篇文章仅讲解Skip-Gram模型。</p>
<a id="more"></a>
<h2 id="数据获取">数据获取</h2>
<p>首先，每次都需要从语料库中抽样一个批次的数据，batch size 为 <span class="math inline">\(\large n\)</span></p>
<p>我采用窗口移动的方式获取，中心词（target）为 <span class="math inline">\(\large w_c\)</span>，窗口（Skip-window）为 <span class="math inline">\(\large m\)</span>，以中心词为中心，两扇窗口分别涵盖 <span class="math inline">\(\large m\)</span> 个上下文词汇，则以中心词为中心的取词跨度（span）是 <span class="math inline">\(\large 2 * m + 1\)</span>。</p>
<p><span class="math display">\[
w_{c-m}, \,.. \, ,w_{c-1}, w_{c}, w_{c+1}, \, .. \,, w_{c+m}
\]</span></p>
<p>有一个参数是取词数量（num-skips），表示每次移动窗口取多少个上下文词汇。以上面为例，假设num-skips为2，那么可能取到的数据是 <span class="math inline">\(\large w_c \rightarrow w_{c+m},\; w_c \rightarrow w_{c+1}\)</span>，没有规定分别取前后多少词，每次在跨度内除中心词外随机取。</p>
<p>中心词每向后移动一次，则重复上面的操作，直到取满批次大小，最少移动 <span class="math inline">\(\large n/\text{num-skips}\)</span> 次。</p>
<p><img src="https://i.loli.net/2018/10/08/5bbb5e794891e.jpeg" width="600px"></p>
<h2 id="算法">算法</h2>
<p>假设批次大小是 <span class="math inline">\(\large n\)</span>，Skip-gram的目标函数为：</p>
<p><span class="math display">\[
\mathcal{L}_{SG}=-\frac{1}{n}\sum_{i=1}^n\sum_{|j|\le c} log\;p(w_{i+j}|w_i)
\]</span></p>
<p>概率函数 <span class="math inline">\(\large p\)</span> 是我们重点讨论的对象。 我们使用两个词向量去拟合，假设词向量的的维度是 <span class="math inline">\(\large E\)</span>，词汇表有 <span class="math inline">\(\large V\)</span> 个单词。</p>
<ul>
<li><span class="math inline">\(\large w_i\)</span>: 词汇表第 <span class="math inline">\(\large i\)</span> 个单词</li>
<li><span class="math inline">\(\large V \in \mathbb{R}^{V \times E}\)</span>: 输入词向量</li>
<li><span class="math inline">\(\large v_i\)</span>: <span class="math inline">\(\large V\)</span>的第 <span class="math inline">\(\large i\)</span> 行，单词 <span class="math inline">\(\large w_i\)</span> 的输入向量表示</li>
<li><span class="math inline">\(\large U \in \mathbb{R}^{V \times E}\)</span>: 输出词词向量</li>
<li><span class="math inline">\(\large u_i\)</span>: <span class="math inline">\(\large U\)</span>的的第 <span class="math inline">\(\large i\)</span> 行，单词 <span class="math inline">\(\large w_i\)</span> 的输出向量表示</li>
</ul>
<p>中心词的词向量由输入词向量获得，上下文词的词向量由输出词向量获得。中心词 <span class="math inline">\(\large c\)</span> 与之对应的上下文词汇 <span class="math inline">\(\large w\)</span> 的词向量的乘积再求和就该中心词的得分 <span class="math inline">\(\large z_c^w = \sum^E_i u_w^i v_c^i\)</span>。</p>
<p>以前会使用softmax函数，但总所周知，softmax函数的计算代价是昂贵的。所以论文作者提出了<strong>负采样（ negative samples）</strong>，称为<strong>负采样Skip-gram（SGNS）</strong>。</p>
<p>假设单词在上下文中，我们称为正样本 <span class="math inline">\(\large w \in D^+\)</span>，若单词不在上下文中，我们称为负样本 <span class="math inline">\(\large \hat w \in D^-\)</span>。每计算一个正样本会携带计算 <span class="math inline">\(\large K\)</span> 个负样本, 这个 <span class="math inline">\(\large K\)</span> 不会很大，一般5~20个，数据集越大，这个值越小。</p>
<p>我们要最大化，下面这个函数</p>
<p><span class="math display">\[
\begin{aligned}
&amp; z_c^w = \sum^E_i u_w^i v_c^i \\
&amp; \hat z_c^{\hat w} = \sum^E_i u_{\hat w}^i v_c^i \\
&amp; \max_{U,V}\;log\;\sigma(z_c^w)+\sum_{(\hat w_k,c)\in D^-}^K log\;\sigma(-\hat z_c^{\hat w_k})
\end{aligned}
\]</span> 即尽量使得正采样的得分变大，而负采样的得分变小。</p>
<p>那么我们可以得到目标函数为，</p>
<p><span class="math display">\[
J = -\frac{1}{n}\sum_{i=1}^n \Big(log\;\sigma(z_{c_i}^{w_i})+\sum_{(\hat w_k,c_i)\in D^-}^K log\;\sigma(\hat z_{c_i}^{\hat w_k})\Big)
\]</span></p>
<p>然后使用随机梯度下降最小化目标函数即可。<a href="https://arxiv.org/abs/1704.03956" target="_blank" rel="noopener">Kaji, et al. (2017)</a> 建议最好使用原生的随机梯度下降，学习率 <span class="math inline">\(\large \alpha\)</span> 为1.0，不需要使用Adam或AdaGrad。实验发现，使用Adam或AdaGrad等得到的效果不如SGD，而且还会降低计算效率。</p>
<p>一般的，我们会以输入向量 <span class="math inline">\(\large V\)</span> 作为最终的词向量。</p>
<h2 id="噪音分布noise-distribution">噪音分布（noise distribution）</h2>
<p>负样本的选取并不是完全随机的，其中定义了一个噪声分布去选取负样本 <a href="https://arxiv.org/abs/1310.4546v1" target="_blank" rel="noopener">[1]</a>。 我们定义<strong>一元组分布</strong>（unigram distribution）为单个单词数量与总单词数量的比值的概率分布，即</p>
<p><span class="math display">\[ 
U(w_i) = \frac{count(w_i)}{\sum_i count(w_i)}
\]</span></p>
<p>而噪声分布定义为</p>
<p><span class="math display">\[
P_n(w_i) = \frac{U(w_i)^{\frac{3}{4}}}{Z}
\]</span></p>
<p>其中 <span class="math inline">\(\large Z\)</span> 是一个扩大系数，一般为 <span class="math inline">\(\text{0.001}\)</span>。 噪音分布的用意是使频繁出现的词更容易被选为负样本，而不频繁出现的词不作为负样本。为什么呢？比如说，类似于<span class="math inline">\(\text{is, a, the}\)</span> 这样的高频词，他们没有实际意义，而且不是我们所关心的，所以应该更多的把他们作为负样本。</p>
<p>为什么要选择<span class="math inline">\(\large \frac{3}{4}\)</span> 次幂呢？在google输入plot y = x^(3/4) and y = x，可以看到曲线的变化趋势</p>
<p><img src="https://i.loli.net/2018/10/08/5bbb5e7907f80.png" width="300px"></p>
<p>其中蓝色曲线是<span class="math inline">\(\large \frac{3}{4}\)</span> 次幂的，越接近1，增量就越小，目的是适当减少超高频词数量。</p>
<p><span class="math inline">\(\large P_n(w_i)\)</span> 在实际使用中就是词汇 <span class="math inline">\(\large w_i\)</span> 在总负样本池中出现的次数。</p>
<h2 id="代码实现">代码实现</h2>
<p>我用pytorch实现了SGNS算法，详见<a href="https://github.com/blackredscarf/pytorch-SkipGram" target="_blank" rel="noopener">Github</a></p>
<h3 id="测试">测试</h3>
<p>经过测试使用了噪音分布后，负样本池的大小减少了非常多，而且 spearmans_rho 得分也提高了一点。</p>
<table>
<thead>
<tr class="header">
<th>eval-data</th>
<th>use-noise</th>
<th>non-noise</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>EN-MC-30</td>
<td>0.2513</td>
<td>0.2405</td>
</tr>
<tr class="even">
<td>EN-MTurk-287</td>
<td>0.2578</td>
<td>0.2357</td>
</tr>
</tbody>
</table>
<p>（词向量300d，训练20万步）</p>
<h2 id="参考文献">参考文献</h2>
<ul>
<li><a href="https://arxiv.org/abs/1310.4546v1" target="_blank" rel="noopener">[1] Distributed Representations of Words and Phrases and their Compositionality. 2013</a></li>
<li><a href="https://arxiv.org/abs/1704.03956" target="_blank" rel="noopener">[2] Incremental Skip-gram Model with Negative Sampling. 2017</a></li>
<li><a href="http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/" target="_blank" rel="noopener">[3] negative sampling tutorial. 2017</a></li>
</ul>

    
    </div>
    
    <div class="columns is-variable is-1 is-multiline is-mobile">
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/NLP/">#NLP</a></span>
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a></span>
    
    </div>
    
    <!-- 
    <span id="post/skip-gram/" class="leancloud_visitors" data-flag-title="负采样的Skip-Gram模型">
        <em class="post-meta-item-text">阅读量 </em>
        <i class="leancloud-visitors-count">1000000</i>
    </span>
     -->
    
    <div class="go-next columns is-mobile is-multiline article-nav">
        <span class="column is-12-mobile is-half-desktop  article-nav-prev">
            
            <a href="/post/glove/">GloVe</a>
            
        </span>
        <span class="column is-12-mobile is-half-desktop  article-nav-next">
            
            <a href="/post/ddpg/">深度确定性策略梯度</a>
            
        </span>
    </div>
    
</article>



<div class="comments">
    <h3 class="title is-4">Comments</h3>
    
<div id="valine-thread"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script>
    new Valine({
        el: '#valine-thread',
        appId: 'DEXiOMuMN86LKmdUtJYX4FRL-MdYXbMMI',
        appKey: 'tPt6E0GhkwXKEBUacbugDcWb',
        notify: true,
        verify: false,
        avatar: '',
        placeholder: 'Say something...',
        meta: ['nick', 'mail'],
        visitor: true,
        lang: ''
    })
</script>


</div>

    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2022 Black Redscarf&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" href="https://github.com/blackredscarf" target="_blank" rel="noopener">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>
</footer>
    <script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/jquery/3.3.1/jquery.min.js"></script>
<script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/" target="_blank" rel="noopener">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/outdated-browser/1.1.5/outdatedbrowser.min.css"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("en-AU");
</script>


    
    
<script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [ ['$','$'],['\\(','\\)'] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: false
        }
    });
</script>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        // ...options...
    });
});
</script>

    
    
<script src="https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/justifiedGallery/3.8.1/jsjustifiedGallery.min.js/jquery."></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    


<script src="/js/script.js"></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</body>
</html>