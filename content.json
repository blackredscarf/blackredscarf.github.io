{"pages":[],"posts":[{"title":"博客折腾记录","text":"hexo博客的一些坑和技巧写在这里。而对于常规操作可以看官方文档。 使用pandoc作为markdown渲染引擎 默认的 hexo-renderer-marked 与 mathjax 和 katex 有很多冲突的问题，所以建议换用 hexo-renderer-pandoc。 确保你已经安装了 pandoc 。然后npm安装即可。 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-pandoc --save 有些主题可能会有js代码检查依赖，把对 hexo-renderer-marked 的检查去掉即可。 使用自定义域名 在github项目的 settings 中设置 custom domain 为域名设置DNS，设置以下A记录： 185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 设置CNAME记录，www.YOURDOMAIN.com 指向 xxx.github.io 在source目录下添加文件CNAME，一行一个写下 www.YOURDOMAIN.com 和 YOURDOMAIN.com","link":"/2018/01/01/blog-log/"},{"title":"CentOS6升级gcc4.9","text":"前段时间在CentOS6集群上跑TensorFlow的时候遇到了glibc和gcc版本过低的问题。本篇讲升级gcc。 问题 如果你的gcc版本过低，在跑一些比较新的软件的时候，可能会报这样的错误： 1libstdc++.so.6: version CXXABI_1.3.7’ not found 那么你就需要更新gcc了，因为CXXABI_x是包含在gcc的libstdc++中的。 查看你的gcc版本 1gcc -v 查看libstdc++版本 1find / -name &quot;libstdc++.so.*&quot; 安装必要依赖包 1yum install gcc gcc-c++ automake autoconf libtool make 下载和解压 12wget ftp://gcc.gnu.org/pub/gcc/releases/gcc-4.9.2/gcc-4.9.2.tar.bz2tar xf gcc-4.9.2.tar.bz2 如果直接从官网下载的话，因为国内网络问题，会慢到怀疑人生。这里提供一个网盘地址。 链接：https://pan.baidu.com/s/1X3cv2eUBh1ViUWOeUQtrCg 密码：ya2y 下载内置依赖 12cd gcc-4.9.2./contrib/download_prerequisites 同样的，下载速度依然龟速。依赖文件包含在上面的网盘地址里了，你可以一并下载下来，再上传到服务器。 打开download_prerequisites这个脚本，发现里面的工作就是下载了几个依赖包到gcc目录外，然后解压，并构建软连接到当前gcc目录。 既然如此，我们就照猫画虎的执行就好了。 12345678tar xf ../mpfr-2.4.2.tar.bz2ln -sf mpfr-2.4.2 mpfrtar xf ../gmp-4.3.2.tar.bz2ln -sf gmp-4.3.2 gmptar xf ../mpc-0.8.1.tar.gzln -sf mpc-0.8.1 mpc 编译安装 1./configure --prefix=/usr --enable-languages=c,c++ --enable--long-long --enable-threads=posix --disable-checking --disable-multilib -j 4 表示开4个线程去编译，一般编译时间大概是20分钟左右。请确保你的系统剩余空间大于6G。如果期间出了错误，一般是缺少依赖和必要库，把依赖安装完后再次执行即可。 12make -j4make install 安装完后，去检查版本是否为4.9.2。 发现 12345678910111213141516Libraries have been installed in: /usr/lib/../lib64If you ever happen to want to link against installed librariesin a given directory, LIBDIR, you must either use libtool, andspecify the full pathname of the library, or use the `-LLIBDIR&apos;flag during linking and do at least one of the following: - add LIBDIR to the `LD_LIBRARY_PATH&apos; environment variable during execution - add LIBDIR to the `LD_RUN_PATH&apos; environment variable during linking - use the `-Wl,-rpath -Wl,LIBDIR&apos; linker flag - have your system administrator add LIBDIR to `/etc/ld.so.conf&apos;See any operating system documentation about shared libraries formore information, such as the ld(1) and ld.so(8) manual pages. 安装完后，会打印这样一段话。这段话的大概意思是linux不会自动去你自己指定的安装目录寻找gcc，你需要在环境变量中设置gcc的安装目录，比如： 1LD_LIBRARY_PATH=/your_gcc_path/ 但是，我们不需要这么干，因为我们安装的时候，路径配置到了gcc的缺省路径上了。","link":"/2018/06/30/centos-upgrade-gcc/"},{"title":"Transformer双向编码器","text":"BERT，完整描述是使用双向编码器的Transformer (Bidirectional Encoder Representations from Transformers)， 是Google在2018年发布的一个神经网络模型 [1]。该模型与以往大多数NLP模型不同，它本身便是一个用于迁移训练的模型。 对于迁移训练，在计算机视觉中迁移训练已经是个常态了，一般都是在经过ImageNet数据训练的预训练模型上进行微调。如今，研究人员在处理NLP问题上也希望能够通过预训练来提高模型能力。而BERT的该论文主要阐述如何在BERT模型上进行预训练，然后基于预训练模型，对于不同任务(task)进行微调。 预训练与微调方法 早于BERT，OpenAI GPT提出了在transformer上进行预训练和微调的方法 [2]，不过与BERT不同的是，GPT采用的是单向transformer以及使用无监督数据来学习语言模型。BERT采用的方法是基于无监督数据采用有监督方法进行预训练，详细方法后面会讲到。 模型结构 bert-1.png 上图是BERT与几个相似模型的对比，只有BERT在所有层级上都加入了左右上下文的信息。 输入表示 bert-2.png 输入向量由三层组合 1. Token Embeddings 即词向量。[CLS] 表示开始标志，[SEP] 用于分割多个句子的标志 2. Segment Embeddings 段落向量。上图中的\\(\\large E_A, E_B\\) 表示两个学习过的句子A和B。为什么这么做后面会讲到。 3. Position Embeddings 位置向量。这里的位置向量不使用余弦函数，而是需要进行训练。 预训练任务 下面会介绍几个用于预训练的任务。 Masked LM BERT 最重要的特点就是双向，能够同时掌握上下文的信息。但是这里就出现了一个问题，convS2S和transformer都在致力于使用masked去清除“过去”的影响，BERT论文中提到这么做是因为在双向多层结构中词汇会在第二层以后看到“自己”，所以要清除这种干扰。 而为了使得BERT这样的双向结构能够进行良好的训练，作者提出了使用Masked LM方法 [3]，该方法就是对于输入的句子，随机遮住(mask)掉一些词汇(token)，然后让模型去预测这个词汇。明显，token被mask掉以后就不会出现自己干扰自己的情况。mask的时候使用[MASK]标记即可。 但是这么做会产生一个弊端，这个[MASK]标记在微调(fine-tuning)中是不会出现的，为了减轻该影响，作者提供了方案： 1. 80% 的情况下，替换为[MASK]，比如 my dog is hairy -&gt; my dog is [MASK] 2. 10% 的情况下，替换为随机词，比如 my dog is hairy -&gt; my dog is apple 3. 10% 的情况下，不替换 下一句预测 就是将句子A和句子B通过[SEP]拼接起来，问你句子B是不是句子A的下一句。 举两个例子： Input = [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP] Label = IsNext Input = [CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds [SEP] Label = NotNext 微调 提取最后一层中 [CLS]标记所在隐藏状态 \\(\\large C \\in \\mathbb{R}^H\\)，以及你自己加上去的权重 \\(\\large W \\in \\mathbb{R}^{K \\times H}\\)，\\(\\large K\\) 即你的分类数。通过Softmax进行预测： \\[ \\large P = softmax(CW^T) \\] 对于超参数的调节，视不同任务而定，作者建议的参数有： Batch size: 16, 32 Learning rate (Adam): 5e-5, 3e-5, 2e-5 Number of epochs: 3, 4 为了方便理解，作者提供对于不同任务的微调的图示： bert-3.png bert-4.png 实验结果 bert-5.png 从上图可以看出，BERT在各项任务上的表现基本是毫无敌手。(以上指标均为GLUE [4]) 总结 BERT的实验结果表明预训练模型的优越性，尽管BERT本身有些瑕疵，但论文本身阐述了诸多预训练的方法和理论，并且表现出强劲的实力，可以说是NLP史上的一座重要的里程碑了。 尽管BERT能够适用于诸多任务，但也有一些任务无法胜任，比如机器翻译…… 参考文献 [1] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. 2018 [2] Improving Language Understandingby Generative Pre-Training. 2018 [3] “Cloze Procedure”: A New Tool for Measuring Readability. 1953 [4] GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding. 2018","link":"/2019/03/28/bi-transformer/"},{"title":"CentOS6升级glibc2.17","text":"前段时间在CentOS6集群上跑TensorFlow的时候遇到了glibc和gcc版本过低的问题。本篇先讲升级glibc。 注意，glibc是linux的核心底层库，一旦升级失败，系统基本就完蛋了。虽然这个教程我有九成把握能升级成功，但是为了避免突发情况，建议你在实际环境上升级之前，先跑一台虚拟机去模拟升级。 检测你的glibc版本 1strings /lib64/libc.so.6 | grep GLIBC 或 1ldd --version 安装必要依赖 1yum install -y wget gcc glibc kernel-devel 方法一：rpm无痛升级 可以直接用社区制作好的rpm包来轻松升级。缺点是社区维护的版本不高，目前centos6最高维护到2.17，你想装2.18的话就没有了。 下载rpm包 1234wget http://copr-be.cloud.fedoraproject.org/results/mosquito/myrepo-el6/epel-6-x86_64/glibc-2.17-55.fc20/glibc-2.17-55.el6.x86_64.rpmwget http://copr-be.cloud.fedoraproject.org/results/mosquito/myrepo-el6/epel-6-x86_64/glibc-2.17-55.fc20/glibc-common-2.17-55.el6.x86_64.rpmwget http://copr-be.cloud.fedoraproject.org/results/mosquito/myrepo-el6/epel-6-x86_64/glibc-2.17-55.fc20/glibc-devel-2.17-55.el6.x86_64.rpmwget http://copr-be.cloud.fedoraproject.org/results/mosquito/myrepo-el6/epel-6-x86_64/glibc-2.17-55.fc20/glibc-headers-2.17-55.el6.x86_64.rpm ### 安装rpm包 1234rpm -Uvh glibc-2.17-55.el6.x86_64.rpm \\glibc-common-2.17-55.el6.x86_64.rpm \\glibc-devel-2.17-55.el6.x86_64.rpm \\glibc-headers-2.17-55.el6.x86_64.rpm 安装完后查看一下当前glibc的版本，如果最高到2.17的话，说明安装成功。 方法二：源码安装glibc 源码安装的缺点就是有些麻烦，要花时间下载以及编译安装。优点就是你想要的所有版本都能安装上。 下载和解压 1234cd /usr/local/srcwget https://mirrors.tuna.tsinghua.edu.cn/gnu/glibc/glibc-2.17.tar.gztar -xf glibc-2.17.tar.gz 配置编译参数 1234mkdir glibc-buildcd glibc-build../glibc-2.17/configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin 编译与安装 12makemake install 安装完后查看一下当前glibc的版本，如果最高到2.17的话，说明安装成功。 问题 你会注意到，配置安装目录的路径是/usr，这么做的目的是在安装的时候直接覆盖旧版的glibc。 网上的一些博客的教程会在配置安装目录的时候，把路径配置到/usr之外的地方，比如 1../configure --prefix=/opt/glibc-2.17 然后把旧的软连接/lib64/libc.so.6删掉，再创建新的软连接。 事实上，这种做法是有风险的，一旦你把软连接删掉，系统在那一瞬间，一些核心的命令和功能就暂时废掉了。一开始我也这么做的，当我马上再创建新的软连接时就报了各种错。为了实验可行性，还导致我重装了好几次系统。","link":"/2018/06/30/centos-upgrade-glibc/"},{"title":"深度确定性策略梯度","text":"虽然DQN的表现很好，但它有一个致命的缺点是无法学习连续动作空间。回想一下，DQN 是根据greddy策略找到最大Q值对应的行为，即 \\(\\large a = \\mathop{argmax}\\limits_{a \\in \\mathcal{A}} Q(s)\\)，也就说每一个行为对应一个Q值，当动作是高维度的或者是连续的，那么DQN的计算代价就很大，甚至无法进行学习。这时使用策略梯度就能很好解决这个问题。我们把环境动作设计成连续的，用动作特征表示一个动作，使用策略梯度，我们不需要计算每一个动作的Q值，而是可以通过参数化近似的办法直接输出一个动作特征，而不是从某个值映射到某个动作。DDPG (Deep Deterministic Policy Gradient)算法很好的弥补了DQN的缺陷。当然，并不是DDPG只能解决连续动作问题，只要把动作特征映射到某一个动作上就能应对非连续动作空间问题了。 算法 DDPG使用演员-评论家模型（actor-critic），设计了4个参数化函数。其中actor包含策略函数 \\(\\large \\mu\\)，目标策略函数 \\(\\large \\mu&#39;\\)，而critic包含Q函数 \\(\\large Q\\)，目标Q函数 \\(\\large Q&#39;\\)。 我们的目标是把 \\(\\large \\mu\\) 参数训练好，因为届时我们获取动作特征的方法是， \\[ a = \\mu(s) \\] 在训练过程中，critic的 \\(\\large Q\\) 的作用是对actor策略 \\(\\large \\mu\\) 进行评估， \\[ \\begin{aligned} a &amp;= \\mu(s) \\\\ q &amp;= Q(s, a) \\end{aligned} \\] 通过 \\(\\large Q(s, a)\\) 可以一个评价当前actor在状态 \\(\\large s\\) 执行动作 \\(\\large a\\) 的分数。 上面提到的参数中，目标参数 \\(\\large \\mu&#39;\\) 和 \\(\\large Q&#39;\\) 作为监督者，以此来计算 \\(\\large \\mu\\) 和 \\(\\large Q\\) 函数的参数梯度。 每一个episode，我们先从经验池 \\(\\large R\\) 中抽样 \\(\\large N\\) 个转移， \\[ (s_i, a_i, r_i, s_{i+1})_i^N \\in R \\] 对于 \\(\\large Q\\) 的损失函数，我们定义为： \\[ \\begin{aligned} &amp; a_{i+1} = \\mu&#39;(s_{i+1}) \\\\ &amp; y_i = r_i + \\gamma Q&#39;(s_{i+1}, a_{i+1}) \\\\ &amp; J = \\frac{1}{N} \\sum_i (y_i-Q(s_i,a))^2 \\end{aligned} \\] 对于 \\(\\large \\mu\\) 的损函数，论文中直接给的是梯度公式。而我参考了其他人的实现，发现他们定义了一个相对简单的损失函数。 \\[ \\begin{aligned} &amp; a_i = \\mu(s_i) \\\\ &amp; J = -\\frac{1}{N} \\sum_i Q(s_i,a_i) \\end{aligned} \\] 大概理解就是，我们设法把 \\(\\large Q(s_i,a_i)\\) 最大化，即通过梯度下降，最小化其负数。 更新完梯度后，需要进行参数软更新（soft-update）： \\[ \\begin{aligned} w^{Q&#39;} &amp;= \\tau \\; w^{Q} + (1-\\tau)w^{Q&#39;} \\\\ w^{\\mu&#39;} &amp;= \\tau \\; w^{\\mu} + (1-\\tau)w^{\\mu&#39;} \\\\ \\tau &amp;\\ll 1 \\end{aligned} \\] 每次更新target参数时，我们不会完全更新，而是保留多一些过往的记忆。 论文中提到，为了让的动作更加丰富，使个体勇于探索，我们要在动作特征上加入噪音。 \\[ \\mu(s) = \\mu(s) + \\epsilon \\; \\mathcal{N} \\] 其中 \\(\\large \\mathcal{N}\\) 使用Ornstein-Uhlenbeck process算法生成噪音。其中 \\(\\large \\epsilon\\) 是一个动态的衰减系数，论文中没有提到，实际使用时如果不加可能导致训练过程非常震荡。 实验细节 论文后面附加部分提供了算法参数的一些细节。 梯度更新使用Adam，actor和critic的学习率分别为1e-4和1e-3。 \\(\\gamma\\) 为0.99 \\(\\large \\tau\\) 为0.001 参数化近似使用神经网络，actor和critic使用三层神经网络，分别是400，300和300个神经元。actor的输出层使用tanh。critic第一层输入状态特征，第一层的输出与动作特征一起输入第二层。 参数初始化，前两层使用fanin_init初始化，最后一层使用区间为[-3e-3, 3e-3]的归一化分布。 Ornstein-Uhlenbeck process的参数中，\\(\\large \\theta\\) 为0.15，\\(\\large \\sigma\\) 为0.2 还有一个就是噪音衰减的问题，这个问题论文中没有提到，但我自己测试时去发现了这个问题不容忽视。\\(\\large \\epsilon\\) 初始值为1，每完成一个episode就减去 \\(\\large d\\)，这个 \\(\\large d\\) 的很难选，假设是0.01，那么100个episode后 \\(\\large \\epsilon\\) 就衰减到0，之后就无法加入噪音了。如果你的模型训练难度较大，要训练几百上千个episode，你必须确保能够持续加入噪音，同时兼顾到训练后期减少噪音的加入。 代码实现 我用pytorch实现了DDPG算法，详见Github 测试 以下是我自己跑的测试结果，测试过程表明某些参数的调节是非常重要的。 MountainCarContinuous-v0 环境细节看这里，小车到达终点就能获得100的奖励。这个环境中小车很容易就找到前往终点的路，所以噪声的衰减可以大一些，设置 \\(\\large d=0.01\\)。 可以看到，小车通过探索很快就找到了终点，并且奖励也接近最优，但因为仍然在往动作中加入噪声，所以小车在尝试有没有更好的路径，经过一番挣扎后，小车发现别的路径都行不通，而此时噪声已经几乎没有了，所以不再进行探索，又回到了之前的获得高奖励的路径上。 如果我们设置 \\(\\large d=0.001\\)，表现如下： 可以发现，噪声衰减调小了，使得小车进行持续的探索。上图经历的episode较少，虽然最终可能找到优秀的路径，但时间代价会很大。原本很快就能解决问题的，没有必要进行长时间的探索。 Pendulum-v0 这个是一个未解决环境，即没有一个奖励区间能说明已经解决。环境细节可以参考这里。 因为环境动作多样化，我们可以进行更多的探索，所以把噪声衰减调节慢一点，设置 \\(\\large d=0.001\\)。 奖励虽然在增长，但一直在负数，后期收敛极慢。而曲线仍然在震荡是因为我们的噪声还没衰减到0。 参考文献 Continuous control with deep reinforcement learning","link":"/2018/09/18/ddpg/"},{"title":"双深度Q网络","text":"本文主要讲一下 DQN 和 DDQN，以及它们的实验对比。 深度Q网络 (DQN) 回顾一下深度Q网络的过程。 从经验池 \\(\\large R\\) 中获取 \\(\\large n\\) 个转移，\\(\\large (s_i, a_i, r_{i+1}, t_i, s_{i+1})\\)，其中 \\(\\large t_i=1\\) 表示 \\(\\large s_i\\) 是结束状态 计算状态 \\(\\large s_i\\) 的预测Q值，\\(\\large y_{pred}^i = Q(s_i)\\)，执行动作 \\(\\large a_i\\) 时的值为 \\(\\large y_{pred}^{a_i}\\) 计算状态 \\(\\large s_{i+1}\\) 的目标Q值，\\(y_{target}^i=Q&#39;(s_i)\\)，取最优动作对应的值，即最大Q值 \\(\\large y_{target}^{max}\\) 计算预期Q值 \\(\\large y_{expected}^i = r_{i+1} + (1-t_i) * \\gamma * y_{target}^{max}\\) \\(\\large n\\) 个转移的均方差损失函数 \\(\\large loss=\\frac{1}{n}\\sum_i (y_{pred}^{a_i} - y_{expected}^i)\\) 使用梯度下降最小化损失函数，更新 \\(\\large Q\\) 网络的梯度值，注意这里不对目标网络 \\(\\large Q&#39;\\) 更新 相隔一定步数后，更新目标网络的参数 \\(\\large Q&#39; = Q\\) 其中，最重要的部分是对于期望Q值的计算，我们把这部分提取出来， \\[ Y_t^{DQN}=R_{t+1} + \\gamma \\max_{a} Q&#39;(S_{t+1}, a; w^-) \\] 使用经验池进行经验重新（experience replay）早在1992年就已经提出，而使用目标网络是在2015年由Mnih等人提出。 双深度Q网络（Double DQN） 不同于DQN，我们的期望Q值的计算为， \\[ Y_t^{DDQN} = R_{t+1} + \\gamma \\max_{a} Q&#39;(S_{t+1}, \\mathop{argmax}\\limits_a Q(S_{t+1}, a; w); w^-) \\] 我们的目标网络输入的不再是指定的 \\(\\large a\\)，而是原本的Q网络的最大Q值对应的动作。 深度Q网络的过度估计 论文中提出，DQN存在普遍的过度估计（overestimations）问题。 假设预测Q值为 \\(\\large Q_t(s, a)\\)，最优价值为 \\(\\large V_*(s)\\) ，每个状态有 \\(\\large m\\) 个动作，则平均误差为 \\[ \\frac{1}{m}\\sum_a(Q_t(s, a) - V_*(s))^2 = C \\] 从误差公式上看，环境的噪声，近似函数等因素都是Q函数参数学习的一部分，意味着任何这些因素都可能导致估值偏差。 对于最大值的估计， \\[ \\max_aQ_t(s,a) - V_*(s) \\ge \\sqrt{\\frac{C}{m+1}} \\] 随着 \\(\\large m\\) 的增大，下界越来越小，而实验结果的表现是随着 \\(\\large m\\) 的增大，估计误差会越来越大，即 \\(\\large Q_t(s,a)\\) 越来越大，产生了所谓的过分乐观（Overoptimism）。 过度乐观的实验 论文中选取的真值函数和近似函数分别为： True Value \\(\\large Q_*(s,a)\\) Approx Function \\(\\large Q_t(s,a)\\) \\(\\large sin(s)\\) \\(\\large W^TX\\) (d=6) \\(\\large 2exp(-s^2)\\) \\(\\large W^TX\\) (d=6) \\(\\large 2exp(-s^2)\\) \\(\\large W^TX\\) (d=9) 测试结果如下，其中每一行是一种真值函数， 第一行第一幅图，描绘了其中一个动作，紫色是真值函数，绿色是拟合函数，可以看出6维的线性回归可以很好的拟合真值。 第一行第二幅图，描绘了10个动作的拟合函数随着的Q值曲线，用黑色描绘的是对应的最大Q值，你会发现最大值普遍大于真值。 第一行第三幅图，描绘了最大Q值与真值的误差，其中橙色曲线是DQN，蓝色曲线是DDQN。明显的，DQN的平均误差要远大于DDQN。 第三行第三幅图，你会发现9维的线性回归的拟合效果远不如6维（第二行第三幅图）。所以说明，有时候复杂的近似函数不一定取得好的效果。 实际效果 在atari游戏上运行对比。 红色是DQN，蓝色是DDQN，其中横线表示无偏估计值。会发现DQN的估计值普遍大于DDQN，而且DQN的估计值偏离很严重。 从上图发现，使用DQN的估计值（浅色区域）非常的不稳地，所以过高的估计值会影响学习效率。 总结 注意一个问题，上面我们一直都在讨论估计值的问题，DDQN能够降低估计值，使得他更接近真值。在实际训练中得到的好处就是训练过程不会太过动荡，也就提高了训练的效率。强化学习与深度学习不同，深度学习会设法得到一个高的准确度。而强化学习中无论是DQN还是DDQN，一直训练下去都能收敛到一个值上，算法的区别更多体现在训练的过程和效率上。 代码实现 我用pytorch分别实现了DQN，DDQN以及用DDQN算法运行atari游戏。详见Github。 测试结果 CartPole-v0 针对CartPole-v0问题，小车上面放着一个杆子，我们的任务是左右移动车子尽量使得杆子在车子上屹立得更久，每一步动作奖励为1，屹立时间越长得到的奖励越多，默认200步结束一个episode，gym认为一个最近100个episode的平均奖励大于195就认为解决。 我分别是用DQN和DDQN训练它，结果如下（蓝色是DQN，橙色是DDQN） PongNoFrameskip-v4 Atari Pong 游戏就是两方在玩类似于乒乓球的游戏，当对方不能打回来，你就得分。目前，这是未解决问题，即没有一个奖励区间能说明解决该问题。 我用DDQN训练2百万帧，情况如下： 训练该环境时遇到了一些问题，一开始发现奖励曲线一直在-20左右徘徊，没有增长的趋势。后来我仔细对比了一下参数，发现Adam的学习率应该使用0.0001，而不是0.001。这也证明了调参的重要性，一个小数点就可能导致模型出现严重的偏差。 参考文献 Deep Reinforcement Learning with Double Q-learning Playing Atari with Deep Reinforcement Learning","link":"/2018/08/30/ddqn/"},{"title":"GloVe","text":"GloVe（Global Vector），是一种结合全局矩阵分解和本地上下文窗口的方法。LSA（latent semantic analysis）虽然能够有效的统计信息，但在词汇类比任务中表现很差。而Skip-gram虽然在词汇类比任务中表现很好，但依赖于窗口的移动，而不能有效统计全局的计数。论文作者认为，全局计数的对数加上双线性回归方法会非常合适。 算法 首先，我们需要对整个语料库建立一个统计全局词频的矩阵，一般称为共现矩阵（Co-ocurrence Matrix）。 假设，语料库有三句话： \\(I \\hspace{0.15cm} enjoy \\hspace{0.15cm} flying\\) \\(I \\hspace{0.15cm} like \\hspace{0.15cm} NLP\\) \\(I \\hspace{0.15cm} like \\hspace{0.15cm} deep \\hspace{0.15cm} learning\\) 那他们的共现矩阵就是： \\(\\large X_{ij}\\) 表示单词 \\(\\large i\\) 在单词 \\(\\large j\\) 上下文出现的次数。你会发现，共现矩阵是对称的（symmetric），因为他同时取左右两边的单词，若只选取左边或右边的任一边，则是非对称的（asymmetric）。 构建词向量（Word Vector）和共现矩阵（Co-ocurrence Matrix）之间的近似关系，论文的作者提出以下的公式可以近似地表达两者之间的关系： \\[ u_i^Tv_j + b_i + \\widetilde b_j \\approx log(X_{ij}) \\tag{1} \\] 这里的 \\(\\large u_i, v_j\\) 与Skip-Grams模型中的意义不同，它仅表示的是单词 \\(\\large i,j\\) 之间的联系，没有中心与周围的区分。（对于公式(1)，论文中做了相关推导，因为推导过程有些复杂，我把这部分放到文章后面。） 他的代价函数是： \\[ J = \\sum_{i,j=1}^V f(X_{ij})(u_i^Tv_j + b_i + \\widetilde b_j - log(X_{ij})) \\] 其中 \\(\\large log(X_{ij}) \\rightarrow log(1 + X_{ij})\\)，这么做的目的是防止出现 \\(\\large log0\\) 的情况。 \\(\\large f(X_{ij})\\) 是一个加权函数（weighting function），有些单词对经常同时出现，那么会导致 \\(\\large X_{ij}\\) 会很大，应该衰减它们；而有些单词对从不一起出现，这些单词对就不应该对代价函数产生任何贡献，它们没必要去计算损失值，这时使用 \\(\\large f(0) = 0\\) 来避免计算。 我们可以采用分段函数： \\[ f(x) = \\begin{cases} (\\frac{x}{x_{max}})^\\alpha &amp; if \\; x &lt; x_{max} \\\\ 1 &amp; otherwise \\end{cases} \\] 函数图像如下： 作者实验 \\(\\large \\alpha\\) 取值 0.75，\\(\\large x_{max}\\) 取值 100。 \\(\\large u_i, v_j\\) 的初始化可以不同，也可以相同。当训练得足够之后，\\(\\large u_i, v_j\\) 与 \\(\\large X_{ij}\\) 相似，而 \\(\\large X_{ij}\\) 是对称的，所以 \\(\\large u_i, v_j\\) 也是对称或接近对称。因为都是学习得到的参数，在我们看来没有本质区别。当初始化不同时，相当于加入了噪音，你可以选择把 \\(\\large e = u + v\\) 作为最终向量，这样有助于提高鲁棒性。 实验结果 论文中展示了glove与word2vec等方法的对比，但其实大家都旗鼓相当。 下图是glove在不同参数的情况下的表现： （图a 展示了向量维度对准确度的影响。图b和图c分别使用对称上下文和非对称上下文在不同窗口大小下的表现。以上所有测试都使用6B (billion) 的语料库） 可以发现最好的参数是300维度，窗口大小为5。再往上增加虽然能提高准确度，但也提高了计算代价，没有必要为了提升一点准确度而产生巨大的计算代价。 公式推导 这里对上面公式(1)进行推导。 论文中举了一个简单的例子： 试问单词 \\(\\large k\\) 应该是哪个单词？我们可以通过 \\(\\large P(k \\vert ice)/P(k \\vert stream)\\) 来判断。当 \\(\\large P_{ik}/P_{jk}\\) 很大的时候，说明 \\(\\large i\\) 与 \\(\\large k\\) 更接近一些。 然后，作者就想到，我们可以用参数去近似这个比值。 \\[ F(w_i, w_j, w_k) = \\frac{P_{ik}}{P_{jk}} \\] \\(\\large F\\) 这里暂且设为未知函数，因为它包含了三个参数，所以我们需要削减一下参数，因为参数是线性的，所以自然可以构造成相减的形式。 \\[ F(w_i - w_j, w_k) = \\frac{P_{ik}}{P_{jk}} \\] 然后我们用内积来表现两个单词向量的近似程度， \\[ F((w_i - w_j)^Tw_k) = \\frac{F(w_i^Tw_k)}{F(w_j^Tw_k)} \\] 提取其中一个单词的 \\(\\large F\\)， \\[ F(w_i^Tw_k) = P_{ik} = \\frac{X_{ik}}{X_i} \\] 我们设 \\(\\large F\\) 为指数函数，则， \\[ w_i^Tw_k = log(P_{ik}) = log(X_{ik}) - log({X_i}) \\] 然后，我们用偏置项来替代 \\(\\large log(X_i)\\)，即 \\[ w_i^Tw_k + b_i + b_k = log(X_{ik}) \\] 就这样，这个公式就被奇异地构造出来了。 代码实现 我自己用python实现了一下，但跑起来后发现这没什么意义。GloVe与Skip-gram不同，他构造共现矩阵需要花费大量时间和内存，这部分极度需要计算性能，用python跑半天都跑不完。 论文作者是使用纯C语言实现的，提供了不少预训练的模型，以及词向量的评估脚本，详见Github。 参考文献 GloVe: Global Vectors for Word Representation - Stanford NLP","link":"/2018/11/20/glove/"},{"title":"卷积序列模型","text":"使用长短时期记忆（LSTM）用于序列模型取得了很好的效果，在2017年由Facebook提出了使用卷积神经网络构建Seq2Seq模型 [1]。循环神经网络通过窗口移动方式输入数据进行训练，当句子有 \\(\\large n\\) 个窗口时，获得对应的特征表示的时间复杂度为 \\(\\large \\mathcal{O}(n)\\)。而使用卷积神经网络进行并行化计算，当卷积核宽度为 \\(\\large k\\) ，其时间复杂度为 \\(\\large \\mathcal{O}(\\frac{n}{k})\\)。 Encoder结构 我们采用一维卷积对序列进行处理，假设输入序列长度为 \\(\\large T\\)，卷积核宽度为 \\(\\large f\\)，边缘为 \\(\\large p\\)，则输出宽度为 \\(\\large T + 2p - f + 1\\)。 源句子的最大序列长度为 \\(\\large T\\), 目标句子的最大序列长度为 \\(\\large T&#39;\\)，批次大小为 \\(\\large B\\)，词向量大小为 \\(\\large E\\)， 源语言词汇数量为 \\(\\large V\\)，目标语言词汇数量为 \\(\\large V&#39;\\)，第一层卷积的通道数为 \\(\\large C\\)。 整个句子的词向量为 \\(\\large X \\leftarrow emb \\in \\mathbb{R}^{T \\times B \\times E}\\) 输入卷积层之前，要先通过一个线性层将维度规范到 $$\\(\\large X \\in \\mathbb{R}^{T \\times B \\times C}\\)，同时对维度做一个转置 \\(\\large X \\in \\mathbb{R}^{B \\times C \\times T}\\) 卷积块带有残差结构 (residual)，所以计算下一个卷积块之前保留一份残差 \\(\\large R \\leftarrow X\\) 在卷积计算时，我们不希望边缘向量产生影响，所以构造一个遮罩矩阵，将 \\(\\large \\langle pad \\rangle\\) 位置值设为0， \\[ mask \\in \\mathbb{R}^{T \\times B} \\begin{cases} 0 &amp; if \\; x = pad \\\\ 1 &amp; otherwise \\end{cases} \\] 转置和扩充维度 \\(\\large mask \\in \\mathbb{R}^{B \\times C \\times T}\\)，把边缘值的通道设为0，\\(\\large X \\leftarrow X \\circ mask\\) 然后把 \\(\\large X\\) 输入到一维卷积中 \\(\\large X \\overset{conv}{\\rightarrow} X \\in \\mathbb{R}^{B \\times T \\times 2C}\\)，这里指定输出通道是输入通道的2倍，而采用Same Convolution，所以序列长度不变 我们使用门控线性单元（Gated Linear Units）对卷积块的输出进行计算 [2]，输出后通道数减半， \\[ \\begin{align} &amp; X \\overset{split}{\\rightarrow}A,B \\in \\mathbb{R}^{B \\times C \\times T} \\\\ &amp; X = A \\circ \\sigma(B) \\end{align} \\] 加上残差，\\(\\large X \\leftarrow X + R\\)；更新残差 \\(\\large R \\leftarrow X\\) 把 \\(\\large X\\) 输入到下一卷积块，即下一层 从最后一个卷积块输出后，再经过线性层得到 \\(\\large O \\in \\mathbb{R}^{B \\times T \\times E}\\) 除了 \\(\\large O\\) 外，还要输出一个向量用于注意力计算 \\(\\large U \\leftarrow O + emb^T\\) 卷积块的计算过程如图所示：（图是我自己画的，如有错误请指出） Decoder结构 Decdoer前面的结构基本与encoder一致，不同处有三个， decoder的卷积层边缘 padding 设置为 kernel_size - 1。当输出时，我们去掉序列最后的 padding 个，以保持输入输出序列相同。这么做是为了确保当前信息不会受未来信息的影响 上述 (5) 计算完GLU后，还要输入到注意力层进行计算，注意力层输出后接上 (6) 上述 (8) 后再经过一个线性层得到对所有词汇的得分矩阵 \\(\\large X \\in \\mathbb{R}^{T&#39; \\times B \\times V&#39;}\\) 注意力层结构 注意力层接收decoder的隐藏状态，目标序列词向量，encoder的输出。 保留一个残差 \\(\\large R \\leftarrow X\\) ，结合decoder的隐藏状态和目标序列词向量，\\(\\large X \\leftarrow W^TX + emb_t ,\\; X \\in \\mathbb{R}^{B \\times T&#39; \\times E}\\) 再与encoder的输出计算注意力得分矩阵 \\(\\large A \\leftarrow X * O,\\; A \\in \\mathbb{R}^{B \\times T&#39; \\times T}\\) 我们不需要 \\(\\large \\langle pad \\rangle\\) 的产生注意，所以把 \\(\\large \\langle pad \\rangle\\) 位置的得分都设置为负无穷 通过softmax对 \\(\\large A\\) 计算注意力分布，得到对齐矩阵 \\(\\large A \\leftarrow softmax(A)\\) 论文中提到，对于注意力的输出，我们还需要计算一个conditional vector，\\(\\large Co \\leftarrow A * U,\\;Co \\in \\mathbb{R}^{B \\times T&#39; \\times E}\\) 最后加上残差后输出 \\(\\large X \\leftarrow W^TX + R,\\; X \\in \\mathbb{R}^{B \\times C \\times T&#39;}\\) 不同于RNN中所有时间步共享一个注意力层，这里的每一个卷积层后面都是一个独立的注意力层，当你有10层卷积层，那么就有10个独立的注意力层。 位置向量（Position Embeddings ） 为了让卷积网络在处理序列时有一种空间感，我们要对词向量加上一个位置向量 \\(\\large emb \\leftarrow emb + pos\\_emb\\)。其中 \\(\\large pos\\_emb\\) 表示对于词汇在该句子的索引编号。 初始化策略 为了抑制加上残差导致数值持续变大而导致高方差，所以每次加上残差或者加上词向量后，都乘以 \\(\\large \\sqrt{0.5}\\) 。 在获得词向量后和输入卷积块之前进行 \\(\\large p=0.1\\) 的dropout正则化 对于卷积块的参数初始化，我们指定其正态分布 \\(\\large \\mathcal{N}(0, \\sqrt{4p/C})\\)，其中乘以 \\(\\large p\\) 是为了抵消dropout时乘以的 \\(\\large 1/p\\)。 线性层初始化参数符合 \\(\\large \\mathcal{N}(0, \\sqrt{(1-p)/N})\\) 词向量和位置向量在 \\(\\large [0, 0.1]\\) 之间均匀分布，并且 \\(\\large \\langle pad \\rangle\\) 对应的词向量设为0 生成（Generation） 在训练时，我们可以一次性把整个目标句子输入到CNN中并行计算，不用像RNN中一步一步的输入，理论上的训练速度会有所提升，实际跑起来后会因为其中大量的注意力层会把训练速度拖慢。 在decoder生成预测序列时，我们需要以递进式的输入到CNN，需要输入 \\(\\large \\frac{T(T-1)}{2}\\) 次，而RNN逐个输入也就 \\(\\large T\\) 次，所以生成速度上，CNN明显要慢。论文中提出的解决方案是把前面序列的卷积参数保留下来，不用重复计算，但并没有详细讲要怎么做，实现起来貌似难度挺大的。 参考文献 [1] Convolutional Sequence to Sequence Learning. 2017 [2] Language Modeling with Gated Convolutional Networks. 2016","link":"/2019/01/27/cnn-seq/"},{"title":"词性标注的简单综述","text":"词性标注(Part-of-Speech Tagging, 简称POS tagging)是将句子中的每个词做一些标记，如动词，名词，副词，形容词等。词性很有用，因为它们揭示了一个单词及其相邻词的很多信息。知道一个单词是名词还是动词可以告诉我们可能的相邻单词(名词前面有限定词和形容词，动词前面有名词)和句法结构单词(名词通常是名词短语的一部分)。一个单词的词性甚至可以在语音识别或合成中发挥作用，因为有些单词不同词性时的读音是不同的。在本综述中，将讨论词性标注的相关算法，比如早期的隐马尔可夫模型 (Hidden Markov Model, HMM)和随机条件域 (Conditional Random Fields, CRF)，以及近几年的神经网络。 1 介绍 词性标注的研究始于20世纪60年代初。词性标注是自然语言处理的重要工具。它是许多NLP应用程序中最简单的统计模型之一。词性标注是信息提取、归纳、检索、机器翻译、语音转换的初始步骤。在上世纪80年代末，人们使用基于隐马尔可夫模型已经使词性标注已经最高达到了95%的准确度。而最近几年，由于神经网络的完善和推广，有些模型可以达到97%的准确度。 2 早期算法 早期解决词性标注问题以隐马尔可夫模型算法为主。 2.1 HMM HMMs和随机语法被广泛应用于文本和语音处理的各种问题，包括主题分割、词性标注、信息提取和句法消歧。 在计算语言学和计算机科学中，隐马尔可夫模型(Hidden Markov models, HMMs)和随机语法被广泛应用于文本和语音处理的各种问题，包括主题分割、词性标注、信息提取和句法消歧。 2.1.1 Hidden Markov Model 马尔可夫链是一个模型，它告诉我们随机变量序列的概率。这些集合可以是表示任何东西的单词、标记或符号，例如天气。马尔可夫链有一个重要的假设，如果我们想在序列中预测未来，重要的是当前状态，当前状态之前的所有状态对未来都没有影响。就好像要预测明天的天气，你可以检查今天的天气，但是你不允许查看昨天的天气。 而马尔可夫假设(Markov Assumption)表示为， \\[ P(q_i=a|q_1 ...q_{i-1} ) = P(q_i=a|q_{i-1} ) \\] 规定，离开给定状态的弧的值之和必须为1。一种马尔可夫链，用于为单词序列\\(w_1...w_n\\)分配一个概率，它表示一个双语言模型，每条边表示概率\\(p(w_i|w_j)\\)。 \\(Q=q_1q_2...q_N\\) 表示N个状态的集合。 \\(A=a_{12}a_{12}...a_{n1}...a_{nm}\\) 一个转移概率矩阵。\\(a_{ij}\\) 表示状态\\(i\\)到状态\\(j\\)的概率。 \\(\\pi=\\pi_1\\pi_2...\\pi_N\\) 一个开始概率分布。 隐马尔可夫模型，即我们不直接观测状态。例如，我们通常不会在文本中观察词性标记。相反，我们看到单词，必须从单词序列中推断出标记。我们将这些标记称为隐藏标记，因为它们没有被观察到。 \\(Q=q_1q_2...q_N\\) 表示N个状态的集合。 \\(A=a_{12}a_{12}...a_{n1}...a_{nm}\\) 一个转移概率矩阵。\\(a_{ij}\\) 表示状态\\(i\\)到状态\\(j\\)的概率。 \\(O=o_1o_2...o_N\\) 序列\\(T\\)的观测。 \\(B=b_i(o_t)\\) 表示由状态\\(i\\)产生的观测值\\(o_t\\)的概率 \\(\\pi=\\pi_1\\pi_2...\\pi_N\\) 一个开始概率分布。 第二个假设：输出观测\\(o_i\\)的概率只取决于产生观测\\(q_i\\)的状态，而不取决于任何其他状态或任何其他观测: \\[ P(o_i|q_1...q_{i-1}) = P(o_i|q_{i-1}) \\] 2.1.2 HMM 标记器 对我们的语料库构建一个词性转移概率矩阵\\(A\\)，包含\\(P(t_i|t_{i-1})\\)，表示给定前一个标记得到当前标记的概率，比如像will这样的情态动词后面很可能跟一个基本形式的动词。 而构建这样的词性转移概率矩阵，需要统计语料库中的词性转移次数， \\[ P(t_i|t_{i-1}) = \\frac{C(t_{i-1},t_i)}{C(t_{i-1})} \\] 比如，MD在WSJ语料库中出现的次数是13124，而MD之后出现will的次数为4046， \\[ P(will|MD) = \\frac{C(MD,will)}{C(MD)} = \\frac{4046}{13124} = 0.31 \\] 2.1.3 HMM 解码器 解码器的定义是：输入一个HMM \\(\\lambda=(A, B)\\) 和观测\\(O=o_1o_2...o_N\\)，找到最有可能的状态序列 \\(Q=q_1q_2...q_N\\)。 n个单词的序列\\(w^n\\)，标记序列\\(t^n\\)，则最终序列结果\\(\\hat{t}^n\\)由： \\[ \\hat{t}^n = \\mathop{argmax}_{t^n}P(t^n|w^n) \\] 有贝叶斯定理可得： \\[ \\hat{t}^n = \\mathop{argmax}_{t^n}\\frac{P(w^n|t^n)P(t^n)}{P(w^n)} \\] 为了简化公式，去掉分母， \\[ \\hat{t}^n = \\mathop{argmax}_{t^n}P(w^n|t^n)P(t^n) \\] 根据第一个假设可知，一个标记只取决于前一个标记。 \\[ P(t^n) \\approx \\prod_{i=1}^n P(t_i|t_{i-1}) \\] 根据第二个假设可知，一个单词(观测)依赖于自身的标记(状态)以及相邻单词及其标记，可得 \\[ P(w^n|t^n) \\approx \\prod_{i=1}^n P(w_i|t_i) \\] 最终可得， \\[ \\hat{t}^n = \\mathop{argmax}_{t^n}P(t^n|w^n) \\approx \\mathop{argmax}_{t^n} \\prod_{i=1}^n P(w_i|t_i)P(t_i|t_{i-1}) \\] 2.1.4 The Viterbi Algorithm 维特比算法建立一个概率矩阵或格子(lattice)，这个格子，的每一列表示一个观测，而每一行表示一个状态。 对于格子中的每一个单元格 \\(v_t(j)\\) 表示HMM \\(\\lambda\\) 经过了\\(t\\)个观测来到状态\\(j\\)中。 \\[ v_t(j)=\\mathop{max}_{q_1...q_{t-1}}P(q_1...q_{t-1},o_1,o_2...o_t,q_t=j|\\lambda) \\] 其中\\(q_1...q_{t-1}\\)表示该单元格经过的所有状态，我们需要像动态规划那样最大化这个状态序列，以便于最终取得最优值。 可得迭代公式， \\[ v_t(j)=\\mathop{max}^N_{i=1}v_{t-1}(i)a_{ij}b_j(o_t) \\] 2.2 CRF HMMs和随机语法是生成模型，将联合概率分配给成对的观察和标签序列。为了定义观测序列和标号序列的联合概率，生成模型需要枚举所有可能的观测序列。特别是，表示多个相互作用的特征或观测值的长期依赖关系是不现实的，因为这类模型的推理问题是难以解决的。 条件随机域 (conditional random fields, CRF) (Lafferty, McCallum &amp; Pereira, 2001)是一个单一的指数模型，可以计算得到给定观测序列的整个标签序列的联合概率。 我们用\\(z = {z_1,..., z_n}\\)表示一个通用的输入序列，\\(z_i\\) 表示第\\(i\\)个单词的向量。\\(y={y_1,...,y_n}\\) 表示\\(z\\)的标签。\\(\\mathcal{Y}(z)\\) 表示\\(z\\)的标签序列集。序列的条件随机域定义为一个条件概率模型 \\(p(y|z;W,b)\\)。给定\\(z\\)与所有可能的\\(y\\)组成： \\[ p(y | z ; W, b)=\\frac{\\prod_{i=1}^{n} \\psi_{i}\\left(y_{i-1}, y_{i}, z\\right)}{\\sum_{y^{\\prime} \\in \\mathcal{Y}(z)} \\prod_{i=1}^{n} \\psi_{i}\\left(y_{i-1}^{\\prime}, y_{i}^{\\prime}, z\\right)} \\] 其中，\\(\\psi_{i}\\left(y_{i-1}, y_{i}, z\\right) = \\exp \\left(W_{y^{\\prime}, y}^{T} z_{i}+b_{y^{\\prime}, y} r\\right)\\) ，而 \\(W_{y^{\\prime}, y}^{T}\\) 与 \\(b_{y^{\\prime}, y}\\) 分布为权重向量和对应标签对的偏移。 对于CRF训练，我们使用最大条件似然估计： \\[ L(W, {b})=\\sum_{i} \\log p(y | {z} ; {W}, {b}) \\] 只要最大化 \\(L(W, {b})\\) 即可。 而解码过程就是搜索具有最高条件概率的标签序列 \\(y^*\\)： \\[ {y}^{*}=\\underset{y \\in \\mathcal{Y}({z})}{\\operatorname{argmax}}\\; p({y} | {z} ; {W}, {b}) \\] 3 神经机器学习 早期算法HMM，CRF等严重依赖手工制作的特性和特定于任务的资源。这种特定于任务的知识开发成本很高，使得序列标记模型难以适应新任务或新领域。近年来，作为输入分布式词表示的非线性神经网络，也称为词嵌入，在NLP问题中得到了广泛的应用，并取得了很大的成功。最近，递归神经网络(RNN) (Goller and Kuchler, 1996) 及其变体，如长短时记忆(LSTM) (Hochreiter and Schmidhuber, 1997)和门控循环神经单元 (GRU) (Cho et al., 2014)在序列数据建模方面取得了巨大的成功。 3.1 LSTM 递归神经网络(RNNs)是一个强大的连接主义模型家族，它通过图中的周期来捕捉时间动态。虽然在理论上，RNNs能够捕获远程依赖关系。但在实践中，由于梯度消失/爆炸问题，基本上失败了。 LSTMs (Hochreiter and Schmidhuber, 1997) 是RNNs的变体，用于处理这些梯度消失问题。基本上，LSTM单元由三个乘法门组成，它们控制信息的比例，以便遗忘和传递到下一个时间步骤。 形式上，LSTM单元在 \\(t\\) 时间步更新的公式为: \\[ \\begin{aligned} \\mathbf{i}_{t} &amp;=\\sigma\\left(\\boldsymbol{W}_{i} \\mathbf{h}_{t-1}+\\boldsymbol{U}_{i \\mathbf{x}_{t}}+\\boldsymbol{b}_{i}\\right) \\\\ \\mathbf{f}_{t} &amp;=\\sigma\\left(\\boldsymbol{W}_{f} \\mathbf{h}_{t-1}+\\boldsymbol{U}_{f} \\mathbf{x}_{t}+\\boldsymbol{b}_{f}\\right) \\\\ \\tilde{\\mathbf{c}}_{t} &amp;=\\tanh \\left(\\boldsymbol{W}_{c-1} \\mathbf{h}_{t-1}+\\boldsymbol{U}_{c} \\mathbf{x}_{t}+\\boldsymbol{b}_{c}\\right) \\\\ \\mathbf{c}_{t} &amp;=\\mathbf{f}_{t} \\odot \\mathbf{c}_{t-1}+\\mathbf{i}_{t} \\odot \\tilde{\\mathbf{c}}_{t} \\\\ \\mathbf{o}_{t} &amp;=\\sigma\\left(\\boldsymbol{W}_{o} \\mathbf{h}_{t-1}+\\boldsymbol{U}_{o} \\mathbf{x}_{t}+\\boldsymbol{b}_{o}\\right) \\\\ \\mathbf{h}_{t} &amp;=\\mathbf{o}_{t} \\odot \\tanh \\left(\\mathbf{c}_{t}\\right) \\end{aligned} \\] 其中 \\(\\sigma\\) 表示 sigmoid 函数，\\(\\odot\\) 表示点积，\\(x_t\\) 是在 \\(t\\) 时间步的输入向量，\\(h_t\\) 是隐藏状态向量，包含了当前及前面所有时间步的信息。\\(U_i, U_f, U_c, U_o\\) 表示不同门的输入权重矩阵。而\\(W_i, W_f, W_c, W_o\\)表示不同门的隐藏状态权重矩阵，\\(b_i, b_f, b_c, b_o\\) 表示偏移向量。 3.1.1 双向 LSTM (BLSTM) 对于许多序列标记任务，访问过去(左)和未来都是有益的。然而，单向LSTM的隐藏状态\\(h_t\\)只从过去获取信息，对未来一无所知。一个优雅的解决方案是双向LSTM，其有效性已经被之前的工作证明 (Chiu et al., 2016)。其通过向前和向后传播的两个隐藏状态，分别捕获过去和未来的信息，然后将这两个隐藏状态连接起来，形成最终的输出。 3.2 用于字符级表示的CNN 卷积神经网络(CNN)是一种从单词字符中提取形态学信息(如单词的前缀或后缀)并将其编码成神经表示的有效方法 (Ma, &amp; Hovy, 2016)。Figure 1 展现了用CNN提取给定单词的字符级表示。 Figure 1: 卷积神经网络用于提取单词的字符级表示。 虚线箭头表示在向CNN输入字符嵌入之前应用了一个dropout层 用CNN计算出每个单词的字符级表示，然后字符级向量表示连接词级向量组成最终的输入向量。 4 训练与评估 词嵌入。 常使用斯坦福大学公开的GloVe 嵌入式系统，该系统训练了来自维基百科和网络文本的60亿个单词 (Pennington et al., 2014)。 数据集。 常使用宾夕法尼亚大学的《华尔街日报》部分 Treebank (PTB) (Marcus et al., 1993)，其中包含45个不同的POS标签。并分为训练集和测试集。而准确度标准采用F1分数。 Mocel Acc. Bi-LSTM (Plank et al., 2016) 97.22 Feed Forward (Vaswani et a. 2016) 97.4 NCRF++ (Yang and Zhang, 2018) 97.49 LSTM-CNNs-CRF (Ma and Hovy, 2016) 97.55 Adversarial Bi-LSTM (Yasunaga et al., 2018) 97.59 Meta BiLSTM (Bohnet et al., 2018) 97.96 Table 1: 近几年的各种模型的测试结果。 5 目前与未来研究 过去以及目前，很多模型都字符级或词级的词嵌入来改善模型性能，还有一些是通过优化语言模型来助力提高词性标注的准确性。未来，一种可能是会通过预训练的强大语言模型或词嵌入来继续提高词性标注性能；二是提出一种新型的网络模型来产生突破性的成果。 参考 Lafferty, J., McCallum, A., &amp; Pereira, F. (2001). Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. Goller, C., &amp; Kuchler, A. (1996, June). Learning task-dependent distributed representations by backpropagation through structure. In Proceedings of International Conference on Neural Networks (ICNN'96) (Vol. 1, pp. 347-352). IEEE. Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780. Cho, K., Van Merriënboer, B., Bahdanau, D., &amp; Bengio, Y. (2014). On the properties of neural machine translation: Encoder-decoder approaches. arXiv preprint arXiv:1409.1259. Chiu, J. P., &amp; Nichols, E. (2016). Named entity recognition with bidirectional LSTM-CNNs. Transactions of the Association for Computational Linguistics, 4, 357-370. Ma, X., &amp; Hovy, E. (2016). End-to-end sequence labeling via bi-directional lstm-cnns-crf. arXiv preprint arXiv:1603.01354. Pennington, J., Socher, R., &amp; Manning, C. (2014). Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532-1543). Marcus, M., Santorini, B., &amp; Marcinkiewicz, M. A. (1993). Building a large annotated corpus of English: The Penn Treebank. Plank, B., Søgaard, A., &amp; Goldberg, Y. (2016). Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss. arXiv preprint arXiv:1604.05529. Vaswani, A., Bisk, Y., Sagae, K., &amp; Musa, R. (2016). Supertagging with lstms. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 232-237). Yang, J., &amp; Zhang, Y. (2018). Ncrf++: An open-source neural sequence labeling toolkit. arXiv preprint arXiv:1806.05626. Yasunaga, M., Kasai, J., &amp; Radev, D. (2017). Robust multilingual part-of-speech tagging via adversarial training. arXiv preprint arXiv:1711.04903. Bohnet, B., McDonald, R., Simoes, G., Andor, D., Pitler, E., &amp; Maynez, J. (2018). Morphosyntactic tagging with a meta-bilstm model over context sensitive token encodings. arXiv preprint arXiv:1805.08237.","link":"/2019/11/23/pos-review/"},{"title":"Linux Select 源码分析","text":"先说明一些关于Linux进程间通信的基本知识：Linux的进程间通信是基于文件的，也可以称之为设备，因为所有设备其实都是文件。描述符其实指的是文件描述符，与文件系统中的一个文件对应，每当你创建出一个描述符，就创建出一个设备驱动进程，该进程一直监听着该文件的变化。 核心 select 源码可以参考这里。 首先select不会一直轮询，轮询一次发现没有可处理的事件，进程就会挂起。那为何select中为何能够感知到某一个描述符发生了变化，其实是文件IO事件触发回调函数唤醒了挂起的select进程。而一旦被唤醒后，则记录一个triggered参数，使得select进程以后不再挂起。 当调用select函数，会创建一个实体缓存队列(poll_wqueues)，尔后会调用 poll_initwait(poll_wqueues) 去初始化该缓存队列，缓存队列将缓存一些实体(poll_table_entry)。（队列大小是有限的，可以通过 poll_table_page 结构体扩容，这个不是重点，这里不展开讲。） 12345678910111213141516171819202122232425262728293031323334353637// poll 表格typedef struct poll_table_struct &#123; poll_queue_proc _qproc; __poll_t _key;&#125; poll_table;// 实体缓存队列struct poll_wqueues &#123; poll_table pt; struct poll_table_page* table; struct task_struct* polling_task; //保存当前调用select的用户进程struct task_struct结构体 int triggered; // 当前用户进程被唤醒后置成1，以免该进程接着进睡眠 int error; // 错误码 int inline_index; // 数组inline_entries的引用下标 struct poll_table_entry inline_entries[N_INLINE_POLL_ENTRIES]; // 实体数组，后面会讲&#125;;// select 的核心函数int do_select(int n, fd_set_bits *fds, struct timespec *end_time)&#123; struct poll_wqueues table; // ... poll_initwait(&amp;table); // ...&#125;void poll_initwait(struct poll_wqueues *pwq)&#123; init_poll_funcptr(&amp;pwq-&gt;pt, __pollwait); // ...&#125;static inline void init_poll_funcptr(poll_table *pt, poll_queue_proc qproc)&#123; pt-&gt;qproc = qproc; pt-&gt;key = ~0UL; /* all events enabled */&#125; 每个设备驱动进程都有一个等待队列，等待队列存放一个等待项(wait_queue_entry_t)，首次发生事件时，会调用 pollwait 往队列放入一个等待项，等待项保存了回调函数，由等待项可会获得一个实体(entry)，实体存放一个指针函数与监听事件掩码key，监听事件掩码的不同二进制位存储是否监听对应事件，由此可知道用户想监听哪些事件。当驱动程序发送IO事件，就会扫描等待队列中的实体，检测是否注册了对应事件，并回调函数，该回调函数是一个唤醒函数(pollwake)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 等待项struct wait_queue_entry &#123; unsigned int flags; void *private; wait_queue_func_t func; // 回调函数 struct list_head entry;&#125;;// 实体struct poll_table_entry &#123; struct file *filp; // 指向特定fd对应的file结构体; unsigned long key; // 等待特定fd对应硬件设备的事件掩码，如POLLIN、 POLLOUT、POLLERR; wait_queue_entry wait; // 需要放入等待队列的等待项 wait_queue_head_t *wait_address; // 设备驱动程序中特定事件的等待队列头&#125;;// 新增一个等待项// pollwait() -&gt; __pollwait()static void __pollwait(struct file *filp, wait_queue_head_t *wait_address, poll_table *p) &#123; struct poll_wqueues *pwq = container_of(p, struct poll_wqueues, pt); struct poll_table_entry *entry = poll_get_entry(pwq); if (!entry) return; get_file(filp); entry-&gt;filp = filp; // 保存对应的file结构体 entry-&gt;wait_address = wait_address; // 保存来自设备驱动程序的等待队列头 entry-&gt;key = p-&gt;key; // 保存对该fd关心的事件掩码 init_waitqueue_func_entry(&amp;entry-&gt;wait, pollwake);// 初始化等待队列项，pollwake是唤醒该等待队列项时候调用的函数 entry-&gt;wait.private = pwq; // 将poll_wqueues作为该等待队列项的私有数据，后面使用 add_wait_queue(wait_address, &amp;entry-&gt;wait);// 将该等待队列项添加到从驱动程序中传递过来的等待队列头中去。&#125;// 唤醒static int pollwake(wait_queue_entry *wait, unsigned mode, int sync, void *key)&#123; struct poll_table_entry *entry; entry = container_of(wait, struct poll_table_entry, wait);// 取得poll_table_entry结构体指针 if (key &amp;&amp; !((unsigned long)key &amp; entry-&gt;key))/*这里的条件判断至关重要，避免应用进程被误唤醒，什么意思？*/ return 0; return __pollwake(wait, mode, sync, key);&#125;static int __pollwake(wait_queue_t *wait, unsigned mode, int sync, void *key)&#123; struct poll_wqueues *pwq = wait-&gt;private; DECLARE_WAITQUEUE(dummy_wait, pwq-&gt;polling_task); smp_wmb(); pwq-&gt;triggered = 1; // select()用户进程只要有被唤醒过，就不可能再次进入睡眠，因为这个标志在睡眠的时候有用 return default_wake_function(&amp;dummy_wait, mode, sync, key); // 默认通用的唤醒函数&#125; 调用结构 123456789101112select() &#123; sys_select(); &#125;sys_select()&#123; // 将用户态参数拷贝到内核 core_sys_select();&#125;core_sys_select()&#123; // 填充 fd_set_bits do_select();&#125;do_select() &#123; // 轮询&#125; do select do_select 是上面我所说的一切工作的外部函数。 接口： 1static int do_select(int n, fd_set_bits *fds, struct timespec64 *end_time) - n 即n个描述符 - fds 类型fd_set_bits是一个结构体，包含了可读，可写，异常三个状态的监听数组，以及三个对应的状态输出数组。 1234typedef struct &#123; unsigned long *in, *out, *ex; unsigned long *res_in, *res_out, *res_ex;&#125; fd_set_bits; - end_time 结束时间 源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160static int do_select(int n, fd_set_bits *fds, struct timespec64 *end_time)&#123; ktime_t expire, *to = NULL; // 实体缓存队列 struct poll_wqueues table; // poll 表格 poll_table* wait; int retval, i, timed_out = 0; u64 slack = 0; __poll_t busy_flag = net_busy_loop_on() ? POLL_BUSY_LOOP : 0; unsigned long busy_start = 0; rcu_read_lock(); // 等一下按位移动查询，所以先计算需要位移的数量 // retval = n * BITS_PER_LONG // BITS_PER_LONG = in | out | exp retval = max_select_fd(n, fds); rcu_read_unlock(); if (retval &lt; 0) return retval; // 注意，这里给了n n = retval; // 初始化等待队列 poll_initwait(&amp;table); // 将初始化后的 poll 表格拿出来，后面传入vfs_poll用于构造等待项 wait = &amp;table.pt; if (end_time &amp;&amp; !end_time-&gt;tv_sec &amp;&amp; !end_time-&gt;tv_nsec) &#123; wait-&gt;_qproc = NULL; timed_out = 1; &#125; if (end_time &amp;&amp; !timed_out) slack = select_estimate_accuracy(end_time); retval = 0; for (;;) &#123; // 轮询 unsigned long *rinp, *routp, *rexp, *inp, *outp, *exp; bool can_busy_loop = false; inp = fds-&gt;in; outp = fds-&gt;out; exp = fds-&gt;ex; rinp = fds-&gt;res_in; routp = fds-&gt;res_out; rexp = fds-&gt;res_ex; // 在描述符数组上按位移动 for (i = 0; i &lt; n; ++rinp, ++routp, ++rexp) &#123; unsigned long in, out, ex, all_bits, bit = 1, j; unsigned long res_in = 0, res_out = 0, res_ex = 0; __poll_t mask; in = *inp++; out = *outp++; ex = *exp++; // 当前描述符监听了哪些事件 all_bits = in | out | ex; if (all_bits == 0) &#123; // 没有监听事件，到下一个描述符 i += BITS_PER_LONG; continue; &#125; for (j = 0; j &lt; BITS_PER_LONG; ++j, ++i, bit &lt;&lt;= 1) &#123; struct fd f; if (i &gt;= n) break; // bit 每次左移一位看看监听哪些事件 if (!(bit &amp; all_bits)) continue; // 找到一个监听的事件，则获取描述符的文件对象 f = fdget(i); if (f.file) &#123; wait_key_set(wait, in, out, bit, busy_flag); // 调用设备驱动程序的poll // 得到事件掩码 // 除了返回掩码外，内部将调用 pollwait() 构造等待项，并放入等待队列 mask = vfs_poll(f.file, wait); fdput(f); // 通过事件掩码查看到底发生了哪些事件 if ((mask &amp; POLLIN_SET) &amp;&amp; (in &amp; bit)) &#123; res_in |= bit; retval++; wait-&gt;_qproc = NULL; &#125; if ((mask &amp; POLLOUT_SET) &amp;&amp; (out &amp; bit)) &#123; res_out |= bit; retval++; wait-&gt;_qproc = NULL; &#125; if ((mask &amp; POLLEX_SET) &amp;&amp; (ex &amp; bit)) &#123; res_ex |= bit; retval++; wait-&gt;_qproc = NULL; &#125; /* got something, stop busy polling */ if (retval) &#123; can_busy_loop = false; busy_flag = 0; /* * only remember a returned * POLL_BUSY_LOOP if we asked for it */ &#125; else if (busy_flag &amp; mask) can_busy_loop = true; &#125; &#125; if (res_in) *rinp = res_in; if (res_out) *routp = res_out; if (res_ex) *rexp = res_ex; cond_resched(); &#125; wait-&gt;_qproc = NULL; // 发现事件 或 超时 或 当前进程有信号要处理 则打断轮询 if (retval || timed_out || signal_pending(current)) break; if (table.error) &#123; retval = table.error; break; &#125; /* only if found POLL_BUSY_LOOP sockets &amp;&amp; not out of time */ if (can_busy_loop &amp;&amp; !need_resched()) &#123; if (!busy_start) &#123; busy_start = busy_loop_current_time(); continue; &#125; if (!busy_loop_timeout(busy_start)) continue; &#125; busy_flag = 0; /* * If this is the first loop and we have a timeout * given, then we convert to ktime_t and set the to * pointer to the expiry value. */ if (end_time &amp;&amp; !to) &#123; expire = timespec64_to_ktime(*end_time); to = &amp;expire; &#125; // 挂起当前进程，直到被唤醒或timeout if (!poll_schedule_timeout(&amp;table, TASK_INTERRUPTIBLE, to, slack)) timed_out = 1; &#125; // 释放实体缓存队列的内存 poll_freewait(&amp;table); return retval;&#125; 总结过程 select调用的基本步骤就是， 调用 select select 轮询一次，找出需要监听事件的描述符，把等待项(监听掩码+回调函数)放到描述符对应的驱动程序的等待队列里边，并返回一个结果掩码，比对所有结果掩码，如果没有发生事件，则挂起。（一般第一次轮询都是挂起的，否则就是第一次轮询之前就发生了事件） 发生IO事件 select进程被唤醒，第二次轮询，找出发生事件的描述符及其具体事件，在fd事件数组上对应位置上做标记。但可能发生的IO事件并非用户要求监听的事件，这时候就不再挂起，而是一直轮询，等待下一次IO事件 清除缓存 返回一个发生事件描述符的数量 用户调用 FD_ISSET() 找出哪个描述符发生事件，处理一些事情 处理完后，又循环回到第1步 参考 https://my.oschina.net/fileoptions/blog/911091 https://elixir.bootlin.com/linux/latest/source/fs/select.c","link":"/2019/09/25/linux-select/"},{"title":"循环神经机器翻译","text":"编码和解码 我们把源句子（source sentence）表示为 \\(\\large (x_1, x_2, \\dots, x_n) \\in x\\), 目标句子（target sentence）表示为 \\(\\large (y_1, y_2, \\dots, y_n) \\in y\\)。 使用编码网路（encoder）对源句子进行编码，使用解码网络（decoder）对源句子的编码进行解码，解码出预测句子。同时，作为监督，把目标句子作为解码网络的输入。 本文主要讲使用循环神经网络构建encoder-decoder模型。 源句子的最大序列长度为 \\(\\large T\\), 目标句子的最大序列长度为 \\(\\large T&#39;\\)，批次大小为 \\(\\large B\\)，词向量大小为 \\(\\large E\\)，RNN的隐藏层大小为 \\(\\large H\\), 源语言词汇数量为 \\(\\large V\\)，目标语言词汇数量为 \\(\\large V&#39;\\)。 一个batch即一个句子，把句子填充到长度为 \\(\\large T\\)， 依次输入一个词，经过词向量 \\(\\large X \\in \\mathbb{R}^{T \\times B \\times E}\\)。 encoder 一次性输入整个源句子 \\(\\large X\\) 和隐藏状态 \\(\\large h \\in \\mathbb{R}^{T \\times B \\times H}\\) encoder 输出 \\(\\large X \\in \\mathbb{R}^{T \\times B \\times H}\\) 和 \\(\\large h \\in \\mathbb{R}^{T \\times B \\times H}\\) decoder 把时间步拆开，每一时间步的输入为上一时间步的隐藏状态和预测词，除了预测词，也可以用目标句子中的词，一个时间步输入数据为 \\(\\large X_i \\in \\mathbb{R}^{1 \\times B \\times E}\\) 和上一时间步的隐藏状态 \\(\\large h \\in \\mathbb{R}^{1 \\times B \\times H}\\) decoder 一个时间步的输出为 $O ^{1 B H} $ 和隐藏状态 \\(\\large h\\)。然后再下一个词向量 \\(\\large X\\) 和 \\(\\large h\\) 输入到下一时间步，执行第4步，直到句子末尾。 我们把decoder每一时间步的输出收集起来 \\(\\large Y \\in \\mathbb{R}^{T&#39; \\times B \\times E}\\) decoder的输出要用于softmax函数，所以每一时间步的输出通过一个线性层 $W ^{H V'} $，则最后的输出 $Y ^{T' B V'} $ 为了方便计算，把decoder的输出压缩成二维 $Y ^{(T' * B) V'} $ ，并使用softmax交叉熵计算损失值 反向传播并梯度更新 seq2seq网络结构如图所示： 因为我们是按批次计算，一个批次中的句子有长有短，为了统一长度，会对所有句子填充 \\(\\large \\langle pad \\rangle\\)。而句子尾部会填充 \\(\\large \\langle eos \\rangle\\) 表示结束，目标句子会在句首加一个\\(\\large \\langle sos \\rangle\\)，通过这个起始标志输出第一个词汇。 目标句子包含 \\(\\large \\langle eos \\rangle\\) , \\(\\large \\langle sos \\rangle\\) 和 \\(\\large \\langle pad \\rangle\\) 的序列长度是 \\(\\large T&#39;\\)， \\[ \\large \\langle sos \\rangle, I, love, you,\\large \\langle eos \\rangle, \\large \\langle pad \\rangle, \\dots, \\large \\langle pad \\rangle \\] 但因为decoder以 \\(\\large \\langle sos \\rangle\\) 为起点，预测输出的是不包含 \\(\\large \\langle sos \\rangle\\) 的，所以计算交叉熵时目标句子应该去掉 \\(\\large \\langle sos \\rangle\\) ，长度变为 \\(\\large T&#39;-1\\)， 但是decoder输出长度为 \\(\\large T&#39;\\)，长度不一致。这时注意到，句子末尾是一堆无意义的 \\(\\large \\langle pad \\rangle\\) ，预测出来的同样是无意义的，所以我们可以把decoder输入的最后一个去掉，这样序列长度就一致了。 注意力机制（Attention Mechanism） 注意力机制有两个作用： 其一，是区分哪部分是重要的。当你听到句子“the ball is on the ﬁeld”，你不会认为这 6 个单词都一样重要。你首先会注意到单词“ball”，“on” 和 “ﬁeld”，因为这些单词你是觉得最“重要”的。类似，Bahdanau 等人注意到使用 RNN 的最终状态作为 Seq2Seq 模型的单个“上下文向量”的缺点：一般对于输入的不同部分具有不同的重要程度。再者，此外，输出的不同部分甚至可以考虑输入的不同部分“重要”。 其二，是具有更长时间的记忆力。你会注意到，当你通过编码网络输出特征向量后，解码阶段就只是根据这个向量来解码，而不再有其他信息。如果我们可以持续从编码网络获取信息，那么我们的预测不是更准确一些吗？就好像人类翻译员，他们肯定也不是只看一眼原句，就能翻译出来，而是对照着原句一个一个翻译。 注意力机制的基本方法就是在解码阶段获取编码阶段的信息。 全局注意力（Global Attention） 所谓全局注意力，即把encoder的所有输出的信息参加到decoder每一时间步的输出的计算中。简单的说就是，当我们预测每一个词时，我们会参考源句子中每一个词，每个源词汇都会得到一个注意力得分（score）。 为了计算注意力，我们把decoder的每一时间步拆开计算。 假设当前时间步的输出为 \\(\\large y \\in \\mathbb{R}^{1 \\times B \\times H}\\)，而encoder的输出为 $O ^{T B H} $。则得分函数可以有以下三种， \\[ score(y, O) = \\begin{cases} y^TO \\\\ (y^TW)^TO \\\\ v^T tanh(W[y;O]) \\end{cases} \\] （一般用第二种） 为了得到得分矩阵，我们计算时会进行转置，\\(\\large y \\in \\mathbb{R}^{B \\times 1 \\times H}\\)， $O ^{B H T} $，矩阵相乘后得到注意力得分 \\(\\large a \\in \\mathbb{R}^{B \\times 1 \\times T}\\)，一般我们还会对它用softmax计算。 我们需要得到一个上下文向量 \\(\\large a \\times O \\rightarrow context \\in \\mathbb{R}^{B \\times 1 \\times H}\\) 把上下文向量与decoder时间步的输出相连，并经过线性层输出注意力向量 \\(\\large concat(context, y)^T W \\rightarrow attn \\in \\mathbb{R}^{B \\times 1 \\times H}\\) 把中间维度去掉后，经过线性层输出 $y ^{B V'} $ 当decoder的 \\(\\large T&#39;\\) 个时间步算完后，我们就能完整的输出序列 \\(\\large Y \\in \\mathbb{R}^{T&#39; \\times B \\times V&#39;}\\) ，以及所有的注意力得分 \\(\\large a\\) 组成了对齐矩阵（alignment matrix）\\(\\large align \\in \\mathbb{R}^{B \\times T&#39; \\times T}\\) 对齐矩阵如图所示： 这个表是将源句子中的单词映射到目标句子中的相应单词，越深色表示相关性越大。 全局注意力网络结构： Input-Feeding Luong et al. (2015) 中提出了Input-Feeding模型 [1]，将注意力向量 \\(\\large attn\\) 和目标词向量连接后作为decoder RNN的输入，即每一时间步的输入为 \\(\\large y \\in \\mathbb{R}^{B \\times 1 \\times (E+H)}\\)。 Teacher Forcing 所谓Teacher Forcing就是对每一时间步的输入使用目标句子中正确的词汇，而不是上一时间步输出的预测词。 Scheduled Sampling Scheduled Sampling 直译“计划抽样” [2]，是介于Teacher Forcing和Without Teacher Forcing之间的方法。我们设置一个使用Teacher Forcing的概率分布，对于每一时间步，我们使用该概率分布来绝对是否使用Teacher Forcing。若使用，我们就输入目标句子中的词汇，否则输入上一时间步的预测词。 论文中的方案是每一时间步就抛硬币选择一次，但实际训练中为了统一，一般是一个batch选择一次。 评估 我们对机器翻译的评估通常会用BLEU算法 [3]。它是一种比较参考翻译（Reference），即人工翻译，与机器翻译的得分算法。 我们对参考句子和预测句子取n元组（n-grams）, 机器翻译结果为 \\(\\large \\hat y\\), 得分为： \\[ P_n = \\frac{\\sum_{ngrams \\in \\hat y}Count_{ref}(ngrams)}{\\sum_{ngrams \\in \\hat y}Count_{MT}(ngrams)} \\] 而BLEU得分的定义为，我们将1至n元组的得分求和再求均值，然后用指数函数放大， \\[ BLEU = \\beta \\; exp({\\frac{1}{n}\\sum_{i=1}^n P_i}) \\] 其中 \\(\\large \\beta\\) 是惩罚因子, 也叫简短惩罚（brevity penalty）。如果你输出了一个非常短的翻译，那么它会更容易得到一个高精确度。因为输出的大部分词可能都出现在参考之中，这时就要对得分进行惩罚。 假设，参考翻译的长度为 \\(\\large r\\), 若有多个句子就取平均值。机器翻译句子长度为 \\(\\large m\\)。 \\[ \\beta = \\begin{cases} 1 &amp; if \\, m &gt; r \\\\ exp(1-\\frac{r}{m}) &amp; otherwise \\end{cases} \\] 如果机器翻译句子大于参考翻译句子长度，我们就不进行惩罚；若小于，\\(\\large 1-\\frac{r}{m}\\) 为负数, 而指数函数会得到一个小数，使得bleu得分降低。 束搜索 （Beam Search） 你也许会直觉的认为，解码器就是直接将每个时间步的输出通过softmax找到最可能的那个词汇即可，这也叫贪心查找（Greedy Search）。但在这只是考虑到一个词的最优选择，而不是整体最优选择。 如图，一句话可能会有成多种翻译版本 如果按照局部最优的选择，那可能会输出第一句。如果按照整体最优，那可能是第三句。而实际上，我们应该考虑整体最优。 \\[ \\mathop{argmax}_{y_1,y_2,...,y_T}\\,P(y_1,y_2,...,y_T|x) \\] 目前比较好的方法是束搜索（Beam search）[4]。 定义一个束宽 \\(\\large b\\)，每个序列得分函数为 \\(\\large F(w)\\)。 第一个时间步输出时，我们会从词汇表 \\(\\large V\\) 中找 \\(\\large b\\) 个得分 \\(\\large F(w)\\) 最大的词汇，加入到对应的序列当中。假设 \\(\\large b = 3\\)，那么就有3个候选序列 \\(\\large s_1(w_1), s_2(w_2), s_3(w_3)\\) 对于第一个时间步的每一个候选，依次输入到第二个时间步中，找得分最大的 \\(\\large b\\) 个词汇分别加入到该候选序列中，由一个候选序列变成 \\(\\large b​\\) 个候选序列 \\[ s(w_1,w_4), s(w_1, w_5), s(w_1, w_6) \\] 总共可以得到 \\(\\large b^2\\) 个候选序列 \\(\\large s_1^1, s_1^2, s_1^3, s_2^1, s_2^2, \\dots\\) 。假设序列长度为 \\(\\large L\\) ，一个序列的总得分为每个词的得分之和 $F(s) = _i^ L F(w_i) $，则该序列的平均得分为 \\(\\large score = F(s) / L\\)。我们保留 \\(\\large b\\) 个平均得分最高的序列，进入下一时间步。 往后重复类似于第2步的操作，当其中一个序列的最后一个词为 \\(\\large \\langle eos \\rangle\\) 时，该序列就停止搜索，直到所有序列都停止或者到达指定的最大长度为止。 最后从 \\(\\large b\\) 个序列选取平均得分最高的序列。 对于得分函数，我们一般使用 \\[ F=log(softmax(Y)) \\] 束搜索一般用在测试阶段。 卷积机器翻译 使用循环神经网络训练的感觉就是慢。使用卷积网络进行机器翻译可以实现并行化，大大提高训练效率。这部分我打算放到另一篇文章中讲。 参考文献 [1] Effective Approaches to Attention-based Neural Machine Translation. 2015 [2] Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks. 2015 [3] BLEU: a Method for Automatic Evaluation of Machine Translation. 2002 [4] Sequence-to-Sequence Learning as Beam-Search Optimization. 2016","link":"/2018/12/31/rnn-nmt/"},{"title":"Raft 与 Etcd","text":"etcd作为一个受到ZooKeeper与doozer启发而催生的项目，拥有与之类似的功能。etcd中的Watcher机制，通过注册与异步通知机制，实现分布式环境下不同系统之间的通知与协调，从而对数据变更做到实时处理。实现方式通常是这样：不同系统都在etcd上对同一个目录进行注册，同时设置Watcher观测该目录的变化（如果对子目录的变化也有需要，可以设置递归模式），当某个系统更新了etcd的目录，那么设置了Watcher的系统就会收到通知，并作出相应处理。 etcd通过Raft算法实现强一致性分布式存储。本文分成两个部分，先讲Raft算法，再讲讲etcd本身的服务。 Raft 算法 Raft 是一种分布式一致性算法，详细可见论文。主要作用是确保分布式系统的一致性问题。考虑主从模式的集群下，服务器挂掉或网络故障等情况发生时如何确保数据安全。在raft中，主节点称为leader，从节点称为follower。 下面我尝试以简洁流畅的语言描述raft算法的各个重要部分。 节点感知 leader和follower需要相互知道的对方存在，一般采用发心跳信息的方式。在raft中，一定是leader主动发心跳信息给follower，然后follower回应。 日志复制 日志复制也叫日志同步或日志分发，之所以叫日志复制是因为总是leader单方面将日志复制到followers上。raft尽可能保证leader和followers的日志进度相同，自动进行着日志的同步。每条日志有一个 log index 参数，严格递增，可以通过该参数判断该follower的同步进度。 可能新增日志的速度快于同步速度，为了确保顺序，会等旧日志同步完后再同步新日志。实现方法可能是，leader与各个follower之间维护一个队列，leader往队列投入日志，followers从队列获取日志。 日志提交 当一个日志同步给超过半数的节点后，leader就可以提交该日志。所谓提交在不同分布式场景中可能有不同的具体表现。比如，在分布式存储中，leader把数据复制到其他节点后并非就真的存储完成，可能只是把数据放到了内存上，只有超过半数节点拥有这一数据才肯定该数据是安全的，然后leader执行提交，通知其他所有节点可以把该数据存储到磁盘上。 follower故障 如果leader给follower发送的心跳信息长时间没有回应，leader就认为该follower挂掉了，并不再给它发送日志数据。 领导选举 leader并非万无一失，也可能会发生故障而挂掉。需要选举出新的leader，每选举出一个leader，每个节点上维护的任期号term加一。 当某个follower持续一定时间没有收到leader的心跳信息，该follower就会认为leader挂掉了，这时他会把自己变成candidate，先把自己的任期号term加一，给自己投一票后广播信息请求其他节点给它投票，信息会携带自己的term和log index。 其他节点收到信息后，先看看自己能不能投，可以重复投给一个节点，但投过一个后就不能投给另一个。可以投票的话就先比较term，如果对方term更大，就投票给它，如果term相同且对方log index更大，同样投票给它，否则拒绝投票 [src]。拒绝投票意味着对方没有资格参与选举，因为它的term或log index落后于人。拒绝投票消息会携带当前term，对方收到消息后就会把自己的term更新为消息中的term，然后把自己变回follower [src]。 如果请求投票期间，candidate收到leader的心跳，也会把自己变回follower [src]。 当一个candidate受到半数以上的投票，它就把自己变成leader并向其他节点发信息宣告这一消息。当然，也可能选举失败，比如若干个candidate拿到相同的票数，并且没有多余的票数，超时之后将自己的term加一并继续新一轮选举。 若是前一个leader在分发某一个日志过程中挂掉了怎么办？如果这条日志还没来得及分发到任何一个节点上，leader就已经挂掉，那么这条日志必然随着leader的挂掉而丢失。如果成功分发到一个节点及以上，那么新leader一定是具有该日志的，否则log index落后一定不会成为leader。新leader发现该日志还没提交，就会分发该日志。与之前任期重复分发了也没关系，反正还没提交写入磁盘。 成员变更 当新加入节点或减少节点，需要将新的集群配置表分发到各个节点上，这一行为与其他日志分发并无不同。如果在分发过程中，leader挂掉了，那么可能发送一种情况是：具有旧集群配置表的节点们会选出一个leader，而新集群配置表的节点们也可能选举出一个leader，最终造成一个集群两个leader。 解决办法是每次只变更一个节点。事实证明，每次只变更一个节点不会产生分裂的情况，因为不会出现同时有两个超过半数以上子集群的存在。假设，我们有一个3节点的集群，然后添加一个节点，leader把变更日志分发到其他2个节点，这时，leader 出现了崩溃，重新选举。这个时候，会有2个结果： 新配置复制到了集群的大多数（大多数的值在这里必须大于2 （包括 leaer））。如果新配置复制到了大多数集群，那么新 leader 肯定使用的是新的配置。 新配置没有复制到集群的大多数。如果新配置没有复制到大多数集群，那么新 leader 肯定使用的是老的配置。 可以参考论文中的图： change-single-server 加入新节点 当加入新节点时，需要告诉leader，有新节点加入，但新节点不会马上加入集群的运作当中。leader会先向改节点同步数据，分多轮同步，直到新节点的数据追上集群的进度才加入集群。 既然日志同步是自动进行的，为什么还要等新节点的进度追上来后才加入集群？存在可能刚加入一个新节点，就有一个节点挂掉了，而新加入节点没有数据是不可用的，相当于同时又两个节点不可用，如果集群当前有4个节点，两个不可用，整个集群就不可用了。 删除节点和网络分区 一个节点被移除后，它自己可能不知道这个情况，它发现没有leader的心跳，自己就会发起选举。如果它的日志不是最新的，它总是无法获得投票，但是又没有leader，所以隔一段时间又再次发起投票，以此类推，老是发起选举会干扰到集群；如果它的日志是最新的，会导致集群节点给它投票，进而可能让一个被移除的节点成为leader。 网络分区类似，在节点通信故障后又重新连回集群后，该节点在多次发起选举后term可能变得很大，收到leader的心跳后发现自己的term比leader的更大，就回应一个消息 [src]，leader发现对方term比自己大，就把自己变成follower [src]，等待一段时间后触发新一轮选举。 为了防止被移除的节点成为leader，每个节点在投票之前需要检查自己在一定时间内有没有收到心跳，如果又收到心跳，说明leader还存活，没必要给别人投票。然而因为被移除节点无法知道自己已经被移除，所以还可以发起选举，虽然不会成为leader，但一直持续下去也不好，最好在移除节点后把该节点上的raft程序停掉。其实可以考虑加一种移除消息类型，当节点收到该消息后把自己停掉就好了。 解决网络分区term过大的问题的办法是PreVote，即预投票。Candidate先发起一次预投票，若是自己能获得大多数节点的投票就发起一次正式投票，如果不能则不能增加term。 Etcd Raft 结构 etcd/raft/node.go中定义了Node接口，定义了一些系列方法，基本涵盖了一个节点在执行raft算法过程中的各种行为。比较关键的几个有 12345678910111213141516type Node interface &#123; // 把用户输入的数据放入raft日志，并投放到集群中。由leader调用 Propose(ctx context.Context, data []byte) error // 发起选举 Campaign(ctx context.Context) error // 接收消息并做出反应 Step(ctx context.Context, msg pb.Message) error // 准备管道。用途很广，可以是准备持久化存储的数据队列，或发往其他成员的消息队列 Ready() &lt;-chan Ready // ...&#125; raft算法的核心实现在raft/raft.go中，其中raft结构体定义了算法运行过程所需数据和操作，RawNode结构体单纯用于持有一个raft实例。node是Node接口的一个实现，持有RawNode实例，又定义了节点相关的操作和行为，可以说是raft算法中一个完整的节点表示，与etcd或其他任何服务都是无关联的，如果你需要自己实现一个基于raft算法的服务，可以直接把node拿来用。 etcdserver\\raft.go中定义了raftNode结构体，这个结构体内嵌了node，又包含了与etcd交互的一些信息和操作，是真正为etcd应用服务的结构体。 PUT流程 写入数据的核心方法是 EtcdServer.processInternalRaftRequestOnce() [src]，把数据传进去，然后调用raftNode.Propose(context, data)，把数据交给raft算法来处理。context用来计时，而且为了知道集群什么时候保存成功，需要给data注册一个ID和对应的channel，raft提交数据后就会往channel发一个消息，EtcdServer会用select监听channel和context，要么成功，要么超时。 持久化 V3版本etcd会在raft提交数据后对数据进行持久化存储，持久化存储使用Boltdb。在持久化的同时，raft也会将数据写入WAL日志和快照，WAL日志是每次写入数据都会记录，而快照则是每隔一定时间就保存一次，并把这段时间的WAL清除掉。 GET流程 client和server建立长连接，阻塞等待server返回事件(event)通知。server内部首先去找到一个跟key绑定的 watcher，然后等待在该watcher的channel上 [src]，直到数据返回。 查找数据的方法以V2版本为例，数据存在内存中，key一般是用/分割，像目录路径一样。在v2store/store.go的internalGet方法中可以看到查找过程，以/切分，然后一层一层地找 [src]。","link":"/2019/12/28/raft-etcd/"},{"title":"负采样的Skip-Gram模型","text":"Word2Vec模型中，主要有Skip-Gram和CBOW两种模型，从直观上理解，Skip-Gram是给定 Input Word 来预测上下文。而CBOW是给定上下文来预测。本篇文章仅讲解Skip-Gram模型。 数据获取 首先，每次都需要从语料库中抽样一个批次的数据，batch size 为 \\(\\large n\\) 我采用窗口移动的方式获取，中心词（target）为 \\(\\large w_c\\)，窗口（Skip-window）为 \\(\\large m\\)，以中心词为中心，两扇窗口分别涵盖 \\(\\large m\\) 个上下文词汇，则以中心词为中心的取词跨度（span）是 \\(\\large 2 * m + 1\\)。 \\[ w_{c-m}, \\,.. \\, ,w_{c-1}, w_{c}, w_{c+1}, \\, .. \\,, w_{c+m} \\] 有一个参数是取词数量（num-skips），表示每次移动窗口取多少个上下文词汇。以上面为例，假设num-skips为2，那么可能取到的数据是 \\(\\large w_c \\rightarrow w_{c+m},\\; w_c \\rightarrow w_{c+1}\\)，没有规定分别取前后多少词，每次在跨度内除中心词外随机取。 中心词每向后移动一次，则重复上面的操作，直到取满批次大小，最少移动 \\(\\large n/\\text{num-skips}\\) 次。 算法 假设批次大小是 \\(\\large n\\)，Skip-gram的目标函数为： \\[ \\mathcal{L}_{SG}=-\\frac{1}{n}\\sum_{i=1}^n\\sum_{|j|\\le c} log\\;p(w_{i+j}|w_i) \\] 概率函数 \\(\\large p\\) 是我们重点讨论的对象。 我们使用两个词向量去拟合，假设词向量的的维度是 \\(\\large E\\)，词汇表有 \\(\\large V\\) 个单词。 \\(\\large w_i\\): 词汇表第 \\(\\large i\\) 个单词 \\(\\large V \\in \\mathbb{R}^{V \\times E}\\): 输入词向量 \\(\\large v_i\\): \\(\\large V\\)的第 \\(\\large i\\) 行，单词 \\(\\large w_i\\) 的输入向量表示 \\(\\large U \\in \\mathbb{R}^{V \\times E}\\): 输出词词向量 \\(\\large u_i\\): \\(\\large U\\)的的第 \\(\\large i\\) 行，单词 \\(\\large w_i\\) 的输出向量表示 中心词的词向量由输入词向量获得，上下文词的词向量由输出词向量获得。中心词 \\(\\large c\\) 与之对应的上下文词汇 \\(\\large w\\) 的词向量的乘积再求和就该中心词的得分 \\(\\large z_c^w = \\sum^E_i u_w^i v_c^i\\)。 以前会使用softmax函数，但总所周知，softmax函数的计算代价是昂贵的。所以论文作者提出了负采样（ negative samples），称为负采样Skip-gram（SGNS）。 假设单词在上下文中，我们称为正样本 \\(\\large w \\in D^+\\)，若单词不在上下文中，我们称为负样本 \\(\\large \\hat w \\in D^-\\)。每计算一个正样本会携带计算 \\(\\large K\\) 个负样本, 这个 \\(\\large K\\) 不会很大，一般5~20个，数据集越大，这个值越小。 我们要最大化，下面这个函数 \\[ \\begin{aligned} &amp; z_c^w = \\sum^E_i u_w^i v_c^i \\\\ &amp; \\hat z_c^{\\hat w} = \\sum^E_i u_{\\hat w}^i v_c^i \\\\ &amp; \\max_{U,V}\\;log\\;\\sigma(z_c^w)+\\sum_{(\\hat w_k,c)\\in D^-}^K log\\;\\sigma(-\\hat z_c^{\\hat w_k}) \\end{aligned} \\] 即尽量使得正采样的得分变大，而负采样的得分变小。 那么我们可以得到目标函数为， \\[ J = -\\frac{1}{n}\\sum_{i=1}^n \\Big(log\\;\\sigma(z_{c_i}^{w_i})+\\sum_{(\\hat w_k,c_i)\\in D^-}^K log\\;\\sigma(\\hat z_{c_i}^{\\hat w_k})\\Big) \\] 然后使用随机梯度下降最小化目标函数即可。Kaji, et al. (2017) 建议最好使用原生的随机梯度下降，学习率 \\(\\large \\alpha\\) 为1.0，不需要使用Adam或AdaGrad。实验发现，使用Adam或AdaGrad等得到的效果不如SGD，而且还会降低计算效率。 一般的，我们会以输入向量 \\(\\large V\\) 作为最终的词向量。 噪音分布（noise distribution） 负样本的选取并不是完全随机的，其中定义了一个噪声分布去选取负样本 [1]。 我们定义一元组分布（unigram distribution）为单个单词数量与总单词数量的比值的概率分布，即 \\[ U(w_i) = \\frac{count(w_i)}{\\sum_i count(w_i)} \\] 而噪声分布定义为 \\[ P_n(w_i) = \\frac{U(w_i)^{\\frac{3}{4}}}{Z} \\] 其中 \\(\\large Z\\) 是一个扩大系数，一般为 \\(\\text{0.001}\\)。 噪音分布的用意是使频繁出现的词更容易被选为负样本，而不频繁出现的词不作为负样本。为什么呢？比如说，类似于\\(\\text{is, a, the}\\) 这样的高频词，他们没有实际意义，而且不是我们所关心的，所以应该更多的把他们作为负样本。 为什么要选择\\(\\large \\frac{3}{4}\\) 次幂呢？在google输入plot y = x^(3/4) and y = x，可以看到曲线的变化趋势 其中蓝色曲线是\\(\\large \\frac{3}{4}\\) 次幂的，越接近1，增量就越小，目的是适当减少超高频词数量。 \\(\\large P_n(w_i)\\) 在实际使用中就是词汇 \\(\\large w_i\\) 在总负样本池中出现的次数。 代码实现 我用pytorch实现了SGNS算法，详见Github 测试 经过测试使用了噪音分布后，负样本池的大小减少了非常多，而且 spearmans_rho 得分也提高了一点。 eval-data use-noise non-noise EN-MC-30 0.2513 0.2405 EN-MTurk-287 0.2578 0.2357 （词向量300d，训练20万步） 参考文献 [1] Distributed Representations of Words and Phrases and their Compositionality. 2013 [2] Incremental Skip-gram Model with Negative Sampling. 2017 [3] negative sampling tutorial. 2017","link":"/2018/10/08/skip-gram/"},{"title":"Transformer模型与自注意力","text":"Facebook激进地使用卷积网络处理NLP问题，意外地取得了很不错的效果。而 Google 一不做二不休，发布了一种新型的网络结构，transformer模型 [1]，该网络结构既不使用RNN，也不使用CNN，而且也获得不错的效果。 1. 模型结构 Encoder和Decoder都是从下往上的栈结构。 1.1 Encoder Encoder有6个相同的独立层，每层有2个子层。第一个子层是多头自注意力层（multi-head self-attention），第二个子层是前馈传播层。 1.2 Decoder Decoder同样有6个相同的独立层，每层有3个子层。第一个子层是遮罩了未来信息的多头自注意力层，第二个子层是联合encoder最后一层的输出的多头注意力层，第三个子层是前馈传播层。 下图是当只有1个独立层时候的网络结构 [1]： 1.3 注意力 注意力函数从 Query, Key, Value 映射到一个输出，这里的 Query, Key, Value 是什么可以先不管，先理解注意力模型的构造。 1.3.1 缩放的点积注意力 （Scaled Dot-Product Attention ） 假设 query, key, value 描述为矩阵 \\(\\large Q, K, V\\), query 和 key 的特征维度是 \\(\\large d_k\\)，而 value 的特征维度是 \\(\\large d_v\\)，那么缩放的点积注意力函数为， \\[ Attention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt{d_k}})V \\] 1.3.2 多头注意力（Multi-Head Attention） 把 query, key, value 从一个大的特征维度映射出多个小特征维度，由 \\(\\large d_{model}\\) 映射到若干个 \\(\\large d_k\\) 或 \\(\\large d_v\\)，假设有 \\(\\large h\\) 个head，那么就有 \\(\\large d_k = d_v = d_{model}/h\\)，每一个 head 进行一次 Scaled Dot-Product Attention，最后再把所有head连接回 \\(\\large d_{model}\\) 维度。 注意力结构如下图： 那么 query, key, value 到底是什么呢？联系上面的模型结构图。 对于encoder来说，第一层输入的 query, key, value 三者皆是源句子的词向量，而后面的层的输入就是上一层的输出。 decoder的第一个子层和encoder相同，三者皆是目标句子的词向量，但是有一个Masked的标识，说明对于decoder来说，我们需要消除该词汇位置往后的参数的影响，消除方法是设置参数为负无穷。 decoder的第二个子层中，query 是第一个子层的输出，key 和 value 是encoder 最后一层的输出。 1.4 前馈传播网络 前馈传播网络包含两个线性层， 计算如下： \\[ FFN(x) = f_2(ReLU(f_1(x))) \\] 1.5 位置编码（Positional Encoding） 一个非RNN的模型无法很好的判断一个词汇在句子中的位置，解决办法是为词向量附加一个位置参数，使得模型能够学习和判断词汇的位置。论文中提出了一个使用余弦和正弦曲线的方法， \\[ PE(pos, 2i)=sin(pos/10000^{2i/d_{model}}) \\\\ PE(pos, 2i+1)=cos(pos/10000^{2i/d_{model}}) \\] 其中 \\(\\large pos\\) 为词在序列的位置，\\(\\large i\\) 为词向量的维度，最后的编码矩阵 \\(\\large PE \\in \\mathbb{R}^{T \\times E}\\)。 假设当前序列长 \\(\\large t\\) ，那么词向量为 \\(\\large emb + PE(t) \\rightarrow emb \\in \\mathbb{R}^{t \\times E}\\) 。 函数对于维度的数值是区分偶数和奇数的，以偶数为例，当位置为1, 5, 10时，位置向量的曲线如图所示， 可以发现，不同位置会进行不同的线性变换，模型会学习到不同位置的固有位置向量，当词向量附加了某一位置向量后，模型就能知道该词在句子中的所在位置。 2. 详细过程 前面大概讲了一下结构和概念，但实际实现模型时还是有很多细节需要弄懂。 源句子的最大序列长度为 \\(\\large T\\), 目标句子的最大序列长度为 \\(\\large T&#39;\\)，批次大小为 \\(\\large B\\)，词向量大小为 \\(\\large E\\)， 源语言词汇数量为 \\(\\large V\\)，目标语言词汇数量为 \\(\\large V&#39;\\)。 2.1 Encoder 计算整个句子的词向量为 \\(\\large dropout(s \\cdot emb(x) + emb\\_pos(x)) \\rightarrow X \\in \\mathbb{R}^{B \\times T \\times E}\\)，\\(\\large s\\) 为 \\(\\large \\sqrt{E}\\) 进入第一子层，记录残差 \\(\\large R \\leftarrow X\\)，标准化 \\(\\large X \\leftarrow Norm(X)\\) 把 \\(\\large X\\) 作为query, key, value，输入自注意力层 \\(\\large Atten(X, X, X) \\rightarrow X \\in \\mathbb{R}^{B \\times T \\times D}\\)，维度 \\(\\large D\\) 即 \\(\\large d_{model}\\) ，和词向量大小 \\(\\large E\\) 是一样的 dropout 正则化后加上残差 \\(\\large X \\leftarrow dropout(X) + R\\) 进入第二子层，记录残差 \\(\\large R \\leftarrow X\\)，标准化 \\(\\large X \\leftarrow Norm(X)\\) 输入到前馈传播网络，再加上残差 \\(\\large X \\leftarrow FFN(X) + R\\) 从步骤 (2) 到 (6) 就结束一个层了，多个层则做同样计算即可。 最终输出为 \\(\\large O \\in \\mathbb{R}^{B \\times T \\times E}\\) 2.2 Decoder Decoder 的第一个子层和第三个子层的步骤和encoder基本相同，这里列出第二子层的过程 记录残差 \\(\\large R \\leftarrow X \\in \\mathbb{R}^{B \\times T&#39; \\times E}\\) [2]，标准化 \\(\\large X \\leftarrow Norm(X)\\) [3] 需要输入到另外一个自注意力层中 \\(\\large Atten(X, O, O) \\rightarrow X\\) dropout 正则化后加上残差 \\(\\large X \\leftarrow dropout(X) + R\\)，再记录残差 \\(\\large R \\leftarrow X\\) 输入到第三子层中 最后一层输出后，通过线性层映射出去 \\(\\large W^TX \\rightarrow X \\in \\mathbb{R}^{B \\times T&#39; \\times V&#39;}\\) 计算softmax交叉熵，反向传播，更新梯度 2.3 Self-Attention \\(\\large d_k = d_v = D / h\\)，则query，key 和 value 分别对应的线性层为 \\(W_q \\in \\mathbb{R}^{D \\times (h\\cdot d)}\\)，\\(W_q \\in \\mathbb{R}^{D \\times (h\\cdot d)}\\) ，\\(W_q \\in \\mathbb{R}^{D \\times (h\\cdot d)}\\) 三个输入参数分别经过线性层后，并把维度转换为 \\(\\large Q, K, V \\in \\mathbb{R}^{B \\times h \\times T \\times d}\\) 矩阵乘法得到相似性得分矩阵 \\(\\large (s \\cdot Q) * K \\rightarrow A \\in \\mathbb{R}^{B \\times h \\times T&#39; \\times T}\\)，其中 \\(\\large s=1/\\sqrt{d}\\) 遮罩计算，\\(\\large A \\leftarrow masked(A)\\)。对于encoder的第一个子层和decoder的第二个子层，把源句子中的边缘位置得分设为负无穷，对于decoder的第一个子层，我们还需要把每一个位置的后面位置的得分设为负无穷。 计算softmax得到归一化的相似性矩阵，\\(\\large A \\leftarrow softmax(A)\\)，正则化 \\(\\large A \\leftarrow dropout(A)\\) 通过矩阵乘法与 value 加权求和，求得注意力得分 \\(\\large A * V \\rightarrow X \\in \\mathbb{R}^{B \\times h \\times T \\times d}\\) 连接 \\(\\large h\\) 个head \\(\\large X \\in \\mathbb{R}^{B \\times T \\times D}\\) 经过一个线性层后输出 \\(\\large W^TX \\rightarrow X \\in \\mathbb{R}^{B \\times T \\times D}\\) 前面提到我们在计算decoder第一子层的注意力时把每一个位置的后面位置的得分设为负无穷，目的是防止未来无用信息的干扰。我们构造该句子的方法是在去边缘的遮罩矩阵基础上，取该矩阵的上三角矩阵，即把相似性矩阵的边缘位置和上三角位置都设为负无穷。 2.4 Feed-Forward Network 构造两个线性层，\\(\\large W_1 \\in \\mathbb{R}^{D \\times F}\\) 和 \\(\\large W_2 \\in \\mathbb{R}^{F \\times D}\\) 。 记录残差 \\(\\large R \\leftarrow X \\in \\mathbb{R}^{B \\times T&#39; \\times D}\\)，标准化 \\(\\large X \\leftarrow Norm(X)\\) 通过第一个线性层并使用ReLU激活函数 \\(\\large ReLu(W_1^TX) \\rightarrow X \\in \\mathbb{R}^{B \\times T&#39; \\times F}\\) 正则化后在通过第二个线性层 \\(\\large W_2^T(dropout(X)) \\rightarrow X \\in \\mathbb{R}^{B \\times T&#39; \\times D}\\) 加上残差后输出 \\(\\large X \\leftarrow X + R\\) 上述过程与论文不同的是，我们把标准化 Layer Normalization 移到注意力层的前面。这么做的原因在于当我不做改动时，模型预测结果很糟糕，结果全是 padding 或 eos，个人感觉是因为残差连接后再标准化会把残差丢失，详细原因也不是很肯定。而tensor2tensor中的建议也是放在前面的，既然如此，我就放在前面了。 2.5 Optimizer 基于Adam，设 \\(\\large \\beta_1 =0.9\\)，\\(\\large \\beta_2=0.98\\) 和 \\(\\large \\epsilon = 10^{-9}\\) ，热更新步为 \\(\\large w=4000\\)，在第 \\(\\large s\\) 步时，则学习率更新规则为， \\[ lr = D^{-0.5} \\cdot min(s^{-0.5}, s \\cdot w^{-1.5}) \\] 学习率的变化如图所示， 4. 参数细节 词向量大小取 512 head的数量为 8 encoder和decoder都是 6 层 前馈传播网络的维度 \\(\\large F\\) 为 2048 dropout 为 0.1 5. 结果 从论文中公示的结果来看，Transformer 模型得到了相当不错的结果，略胜 ConvS2S 一筹。 6. 自注意力的有效性 自注意力（self-Attention）主要特点是解决了远程依赖问题（long-range dependencies）。信号传递的距离越远，信号就变得越弱，远程依赖就越弱。RNN需要通过时间步的计算传递，信号传递长度是 \\(\\large \\mathcal{O}(n)\\)，而自注意力是把整个序列的信号进行前一层和后一层的直接计算，所以只要 \\(\\large \\mathcal{O}(1)\\)。 参考文献 [1] Attention Is All You Need. 2017 [2] Deep Residual Learning for Image Recognition. 2015 [3] Layer Normalization. 2016","link":"/2019/02/27/transformer/"}],"tags":[{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"深度学习","slug":"深度学习","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"强化学习","slug":"强化学习","link":"/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"I/O","slug":"I-O","link":"/tags/I-O/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"categories":[{"name":"blog","slug":"blog","link":"/categories/blog/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"NLP","slug":"NLP","link":"/categories/NLP/"},{"name":"强化学习","slug":"强化学习","link":"/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]}