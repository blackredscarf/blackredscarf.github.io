<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
<title>词性标注的简单综述 - 绯色的魔法世界</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">




<meta name="description" content="">





    <meta name="description" content="词性标注(Part-of-Speech Tagging, 简称POS tagging)是将句子中的每个词做一些标记，如动词，名词，副词，形容词等。词性很有用，因为它们揭示了一个单词及其相邻词的很多信息。知道一个单词是名词还是动词可以告诉我们可能的相邻单词(名词前面有限定词和形容词，动词前面有名词)和句法结构单词(名词通常是名词短语的一部分)。一个单词的词性甚至可以在语音识别或合成中发挥作用，因为有">
<meta name="keywords" content="NLP,深度学习,机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="词性标注的简单综述">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;11&#x2F;23&#x2F;pos-review&#x2F;index.html">
<meta property="og:site_name" content="绯色的魔法世界">
<meta property="og:description" content="词性标注(Part-of-Speech Tagging, 简称POS tagging)是将句子中的每个词做一些标记，如动词，名词，副词，形容词等。词性很有用，因为它们揭示了一个单词及其相邻词的很多信息。知道一个单词是名词还是动词可以告诉我们可能的相邻单词(名词前面有限定词和形容词，动词前面有名词)和句法结构单词(名词通常是名词短语的一部分)。一个单词的词性甚至可以在语音识别或合成中发挥作用，因为有">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;s2.ax1x.com&#x2F;2019&#x2F;11&#x2F;23&#x2F;MHXD0A.png">
<meta property="og:image" content="https:&#x2F;&#x2F;i.loli.net&#x2F;2019&#x2F;05&#x2F;20&#x2F;5ce23f703124d64378.png">
<meta property="og:updated_time" content="2019-11-30T14:49:34.716Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;s2.ax1x.com&#x2F;2019&#x2F;11&#x2F;23&#x2F;MHXD0A.png">





<link rel="icon" href="https://s1.ax1x.com/2020/07/25/aSC9Cn.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/highlight.js/10.1.1/styles/atom-one-light.min.css">

<link rel="stylesheet" href="/css/style.css">

<script defer src="https://cdn.bootcdn.net/ajax/libs/font-awesome/5.14.0/js/all.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


    
    
    
    
    
    
    
    
    
    

    


</head>
<body>
    

<!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="top-title-line">
        <div class="top-title">
            <a href="/"><span>绯色的魔法世界</span></a>
        </div>
    </div>
    <div class="nav-tool-line">
        <div class="nav-tool">
            
            <a class="navbar-item search" title="Search" href="javascript:;" target="_blank" rel="noopener">
                <i class="fas fa-search"></i>
            </a>
            
            
            <a class="navbar-item" title="GitHub" href="https://github.com/blackredscarf" target="_blank" rel="noopener">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>    
    </div>
    <div class="container">
        <div class="navbar-brand">
            <!-- <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a> -->
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/">Home</a>
            
            <a class="navbar-item "
               href="/archives">归档</a>
            
            <a class="navbar-item "
               href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F">操作系统</a>
            
            <a class="navbar-item "
               href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F">分布式</a>
            
            <a class="navbar-item "
               href="/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E8%AE%BE%E8%AE%A1">算法与设计</a>
            
            <a class="navbar-item "
               href="/categories/NLP">NLP</a>
            
            <a class="navbar-item "
               href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
            
        </div>
        
        
    </div>
</nav>

    <section class="section">
    <div class="container">
    
<div class="article-cover">
   <img class="article-cover-img" src="https://s2.ax1x.com/2019/11/23/MHq7tK.jpg"> 
</div>

<article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            词性标注的简单综述
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            2019-11-23
            <!-- <time datetime="2019-11-22T16:00:00.000Z" itemprop="datePublished">Nov 23 2019</time> -->
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/NLP/">NLP</a><span>,</span><a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span>,</span><a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
        </span>
        
        <!--  -->
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>词性标注(Part-of-Speech Tagging, 简称POS tagging)是将句子中的每个词做一些标记，如动词，名词，副词，形容词等。词性很有用，因为它们揭示了一个单词及其相邻词的很多信息。知道一个单词是名词还是动词可以告诉我们可能的相邻单词(名词前面有限定词和形容词，动词前面有名词)和句法结构单词(名词通常是名词短语的一部分)。一个单词的词性甚至可以在语音识别或合成中发挥作用，因为有些单词不同词性时的读音是不同的。在本综述中，将讨论词性标注的相关算法，比如早期的隐马尔可夫模型 (Hidden Markov Model, HMM)和随机条件域 (Conditional Random Fields, CRF)，以及近几年的神经网络。</p>
<a id="more"></a>
<h2 id="介绍">1 介绍</h2>
<p>词性标注的研究始于20世纪60年代初。词性标注是自然语言处理的重要工具。它是许多NLP应用程序中最简单的统计模型之一。词性标注是信息提取、归纳、检索、机器翻译、语音转换的初始步骤。在上世纪80年代末，人们使用基于隐马尔可夫模型已经使词性标注已经最高达到了95%的准确度。而最近几年，由于神经网络的完善和推广，有些模型可以达到97%的准确度。</p>
<h2 id="早期算法">2 早期算法</h2>
<p>早期解决词性标注问题以隐马尔可夫模型算法为主。</p>
<h3 id="hmm">2.1 HMM</h3>
<p>HMMs和随机语法被广泛应用于文本和语音处理的各种问题，包括主题分割、词性标注、信息提取和句法消歧。</p>
<p>在计算语言学和计算机科学中，隐马尔可夫模型(Hidden Markov models, HMMs)和随机语法被广泛应用于文本和语音处理的各种问题，包括主题分割、词性标注、信息提取和句法消歧。</p>
<h4 id="hidden-markov-model">2.1.1 Hidden Markov Model</h4>
<p>马尔可夫链是一个模型，它告诉我们随机变量序列的概率。这些集合可以是表示任何东西的单词、标记或符号，例如天气。马尔可夫链有一个重要的假设，如果我们想在序列中预测未来，重要的是当前状态，当前状态之前的所有状态对未来都没有影响。就好像要预测明天的天气，你可以检查今天的天气，但是你不允许查看昨天的天气。</p>
<p>而马尔可夫假设(Markov Assumption)表示为，</p>
<p><span class="math display">\[
P(q_i=a|q_1 ...q_{i-1} ) = P(q_i=a|q_{i-1} )
\]</span></p>
<p>规定，离开给定状态的弧的值之和必须为1。一种马尔可夫链，用于为单词序列<span class="math inline">\(w_1...w_n\)</span>分配一个概率，它表示一个双语言模型，每条边表示概率<span class="math inline">\(p(w_i|w_j)\)</span>。</p>
<ul>
<li><span class="math inline">\(Q=q_1q_2...q_N\)</span> 表示N个状态的集合。</li>
<li><span class="math inline">\(A=a_{12}a_{12}...a_{n1}...a_{nm}\)</span> 一个转移概率矩阵。<span class="math inline">\(a_{ij}\)</span> 表示状态<span class="math inline">\(i\)</span>到状态<span class="math inline">\(j\)</span>的概率。</li>
<li><span class="math inline">\(\pi=\pi_1\pi_2...\pi_N\)</span> 一个开始概率分布。</li>
</ul>
<p>隐马尔可夫模型，即我们不直接观测状态。例如，我们通常不会在文本中观察词性标记。相反，我们看到单词，必须从单词序列中推断出标记。我们将这些标记称为隐藏标记，因为它们没有被观察到。</p>
<ul>
<li><span class="math inline">\(Q=q_1q_2...q_N\)</span> 表示N个状态的集合。</li>
<li><span class="math inline">\(A=a_{12}a_{12}...a_{n1}...a_{nm}\)</span> 一个转移概率矩阵。<span class="math inline">\(a_{ij}\)</span> 表示状态<span class="math inline">\(i\)</span>到状态<span class="math inline">\(j\)</span>的概率。</li>
<li><span class="math inline">\(O=o_1o_2...o_N\)</span> 序列<span class="math inline">\(T\)</span>的观测。</li>
<li><span class="math inline">\(B=b_i(o_t)\)</span> 表示由状态<span class="math inline">\(i\)</span>产生的观测值<span class="math inline">\(o_t\)</span>的概率</li>
<li><span class="math inline">\(\pi=\pi_1\pi_2...\pi_N\)</span> 一个开始概率分布。</li>
</ul>
<p>第二个假设：输出观测<span class="math inline">\(o_i\)</span>的概率只取决于产生观测<span class="math inline">\(q_i\)</span>的状态，而不取决于任何其他状态或任何其他观测:</p>
<p><span class="math display">\[
P(o_i|q_1...q_{i-1}) = P(o_i|q_{i-1})
\]</span></p>
<h4 id="hmm-标记器">2.1.2 HMM 标记器</h4>
<p>对我们的语料库构建一个词性转移概率矩阵<span class="math inline">\(A\)</span>，包含<span class="math inline">\(P(t_i|t_{i-1})\)</span>，表示给定前一个标记得到当前标记的概率，比如像will这样的情态动词后面很可能跟一个基本形式的动词。</p>
<p>而构建这样的词性转移概率矩阵，需要统计语料库中的词性转移次数，</p>
<p><span class="math display">\[
P(t_i|t_{i-1}) = \frac{C(t_{i-1},t_i)}{C(t_{i-1})}
\]</span></p>
<p>比如，MD在WSJ语料库中出现的次数是13124，而MD之后出现will的次数为4046，</p>
<p><span class="math display">\[
P(will|MD) = \frac{C(MD,will)}{C(MD)}
= \frac{4046}{13124} = 0.31
\]</span></p>
<h4 id="hmm-解码器">2.1.3 HMM 解码器</h4>
<p>解码器的定义是：输入一个HMM <span class="math inline">\(\lambda=(A, B)\)</span> 和观测<span class="math inline">\(O=o_1o_2...o_N\)</span>，找到最有可能的状态序列 <span class="math inline">\(Q=q_1q_2...q_N\)</span>。</p>
<p>n个单词的序列<span class="math inline">\(w^n\)</span>，标记序列<span class="math inline">\(t^n\)</span>，则最终序列结果<span class="math inline">\(\hat{t}^n\)</span>由：</p>
<p><span class="math display">\[
\hat{t}^n = \mathop{argmax}_{t^n}P(t^n|w^n)
\]</span></p>
<p>有贝叶斯定理可得：</p>
<p><span class="math display">\[
\hat{t}^n = \mathop{argmax}_{t^n}\frac{P(w^n|t^n)P(t^n)}{P(w^n)}
\]</span></p>
<p>为了简化公式，去掉分母，</p>
<p><span class="math display">\[
\hat{t}^n = \mathop{argmax}_{t^n}P(w^n|t^n)P(t^n)
\]</span></p>
<p>根据第一个假设可知，一个标记只取决于前一个标记。</p>
<p><span class="math display">\[
P(t^n) \approx \prod_{i=1}^n P(t_i|t_{i-1})
\]</span></p>
<p>根据第二个假设可知，一个单词(观测)依赖于自身的标记(状态)以及相邻单词及其标记，可得</p>
<p><span class="math display">\[
P(w^n|t^n) \approx \prod_{i=1}^n P(w_i|t_i)
\]</span></p>
<p>最终可得，</p>
<p><span class="math display">\[
\hat{t}^n = \mathop{argmax}_{t^n}P(t^n|w^n) \approx  \mathop{argmax}_{t^n} \prod_{i=1}^n P(w_i|t_i)P(t_i|t_{i-1})
\]</span></p>
<h4 id="the-viterbi-algorithm">2.1.4 The Viterbi Algorithm</h4>
<p>维特比算法建立一个概率矩阵或格子(lattice)，这个格子，的每一列表示一个观测，而每一行表示一个状态。</p>
<p>对于格子中的每一个单元格 <span class="math inline">\(v_t(j)\)</span> 表示HMM <span class="math inline">\(\lambda\)</span> 经过了<span class="math inline">\(t\)</span>个观测来到状态<span class="math inline">\(j\)</span>中。</p>
<p><span class="math display">\[
v_t(j)=\mathop{max}_{q_1...q_{t-1}}P(q_1...q_{t-1},o_1,o_2...o_t,q_t=j|\lambda)
\]</span></p>
<p>其中<span class="math inline">\(q_1...q_{t-1}\)</span>表示该单元格经过的所有状态，我们需要像动态规划那样最大化这个状态序列，以便于最终取得最优值。</p>
<p><img src="https://s2.ax1x.com/2019/11/23/MHXD0A.png"></p>
<p>可得迭代公式，</p>
<p><span class="math display">\[
v_t(j)=\mathop{max}^N_{i=1}v_{t-1}(i)a_{ij}b_j(o_t)
\]</span></p>
<h3 id="crf">2.2 CRF</h3>
<p>HMMs和随机语法是生成模型，将联合概率分配给成对的观察和标签序列。为了定义观测序列和标号序列的联合概率，生成模型需要枚举所有可能的观测序列。特别是，表示多个相互作用的特征或观测值的长期依赖关系是不现实的，因为这类模型的推理问题是难以解决的。</p>
<p>条件随机域 (conditional random fields, CRF) (Lafferty, McCallum &amp; Pereira, 2001)是一个单一的指数模型，可以计算得到给定观测序列的整个标签序列的联合概率。</p>
<p>我们用<span class="math inline">\(z = {z_1,..., z_n}\)</span>表示一个通用的输入序列，<span class="math inline">\(z_i\)</span> 表示第<span class="math inline">\(i\)</span>个单词的向量。<span class="math inline">\(y={y_1,...,y_n}\)</span> 表示<span class="math inline">\(z\)</span>的标签。<span class="math inline">\(\mathcal{Y}(z)\)</span> 表示<span class="math inline">\(z\)</span>的标签序列集。序列的条件随机域定义为一个条件概率模型 <span class="math inline">\(p(y|z;W,b)\)</span>。给定<span class="math inline">\(z\)</span>与所有可能的<span class="math inline">\(y\)</span>组成：</p>
<p><span class="math display">\[
p(y | z ; W, b)=\frac{\prod_{i=1}^{n} \psi_{i}\left(y_{i-1}, y_{i}, z\right)}{\sum_{y^{\prime} \in \mathcal{Y}(z)} \prod_{i=1}^{n} \psi_{i}\left(y_{i-1}^{\prime}, y_{i}^{\prime}, z\right)}
\]</span></p>
<p>其中，<span class="math inline">\(\psi_{i}\left(y_{i-1}, y_{i}, z\right) = \exp \left(W_{y^{\prime}, y}^{T} z_{i}+b_{y^{\prime}, y} r\right)\)</span> ，而 <span class="math inline">\(W_{y^{\prime}, y}^{T}\)</span> 与 <span class="math inline">\(b_{y^{\prime}, y}\)</span> 分布为权重向量和对应标签对的偏移。</p>
<p>对于CRF训练，我们使用最大条件似然估计：</p>
<p><span class="math display">\[
L(W, {b})=\sum_{i} \log p(y | {z} ; {W}, {b})
\]</span></p>
<p>只要最大化 <span class="math inline">\(L(W, {b})\)</span> 即可。</p>
<p>而解码过程就是搜索具有最高条件概率的标签序列 <span class="math inline">\(y^*\)</span>：</p>
<p><span class="math display">\[
{y}^{*}=\underset{y \in \mathcal{Y}({z})}{\operatorname{argmax}}\; p({y} | {z} ; {W}, {b})
\]</span></p>
<h2 id="神经机器学习">3 神经机器学习</h2>
<p>早期算法HMM，CRF等严重依赖手工制作的特性和特定于任务的资源。这种特定于任务的知识开发成本很高，使得序列标记模型难以适应新任务或新领域。近年来，作为输入分布式词表示的非线性神经网络，也称为词嵌入，在NLP问题中得到了广泛的应用，并取得了很大的成功。最近，递归神经网络(RNN) (Goller and Kuchler, 1996) 及其变体，如长短时记忆(LSTM) (Hochreiter and Schmidhuber, 1997)和门控循环神经单元 (GRU) (Cho et al., 2014)在序列数据建模方面取得了巨大的成功。</p>
<h3 id="lstm">3.1 LSTM</h3>
<p>递归神经网络(RNNs)是一个强大的连接主义模型家族，它通过图中的周期来捕捉时间动态。虽然在理论上，RNNs能够捕获远程依赖关系。但在实践中，由于梯度消失/爆炸问题，基本上失败了。</p>
<p>LSTMs (Hochreiter and Schmidhuber, 1997) 是RNNs的变体，用于处理这些梯度消失问题。基本上，LSTM单元由三个乘法门组成，它们控制信息的比例，以便遗忘和传递到下一个时间步骤。</p>
<p>形式上，LSTM单元在 <span class="math inline">\(t\)</span> 时间步更新的公式为:</p>
<p><span class="math display">\[
\begin{aligned} \mathbf{i}_{t} &amp;=\sigma\left(\boldsymbol{W}_{i} \mathbf{h}_{t-1}+\boldsymbol{U}_{i \mathbf{x}_{t}}+\boldsymbol{b}_{i}\right) \\ 
\mathbf{f}_{t} &amp;=\sigma\left(\boldsymbol{W}_{f} \mathbf{h}_{t-1}+\boldsymbol{U}_{f} \mathbf{x}_{t}+\boldsymbol{b}_{f}\right) \\ 
\tilde{\mathbf{c}}_{t} &amp;=\tanh \left(\boldsymbol{W}_{c-1} \mathbf{h}_{t-1}+\boldsymbol{U}_{c} \mathbf{x}_{t}+\boldsymbol{b}_{c}\right) \\ 
\mathbf{c}_{t} &amp;=\mathbf{f}_{t} \odot \mathbf{c}_{t-1}+\mathbf{i}_{t} \odot \tilde{\mathbf{c}}_{t} \\ 
\mathbf{o}_{t} &amp;=\sigma\left(\boldsymbol{W}_{o} \mathbf{h}_{t-1}+\boldsymbol{U}_{o} \mathbf{x}_{t}+\boldsymbol{b}_{o}\right) \\ 
\mathbf{h}_{t} &amp;=\mathbf{o}_{t} \odot \tanh \left(\mathbf{c}_{t}\right) \end{aligned}
\]</span></p>
<p>其中 <span class="math inline">\(\sigma\)</span> 表示 sigmoid 函数，<span class="math inline">\(\odot\)</span> 表示点积，<span class="math inline">\(x_t\)</span> 是在 <span class="math inline">\(t\)</span> 时间步的输入向量，<span class="math inline">\(h_t\)</span> 是隐藏状态向量，包含了当前及前面所有时间步的信息。<span class="math inline">\(U_i, U_f, U_c, U_o\)</span> 表示不同门的输入权重矩阵。而<span class="math inline">\(W_i, W_f, W_c, W_o\)</span>表示不同门的隐藏状态权重矩阵，<span class="math inline">\(b_i, b_f, b_c, b_o\)</span> 表示偏移向量。</p>
<h4 id="双向-lstm-blstm">3.1.1 双向 LSTM (BLSTM)</h4>
<p>对于许多序列标记任务，访问过去(左)和未来都是有益的。然而，单向LSTM的隐藏状态<span class="math inline">\(h_t\)</span>只从过去获取信息，对未来一无所知。一个优雅的解决方案是双向LSTM，其有效性已经被之前的工作证明 (Chiu et al., 2016)。其通过向前和向后传播的两个隐藏状态，分别捕获过去和未来的信息，然后将这两个隐藏状态连接起来，形成最终的输出。</p>
<h3 id="用于字符级表示的cnn">3.2 用于字符级表示的CNN</h3>
<p>卷积神经网络(CNN)是一种从单词字符中提取形态学信息(如单词的前缀或后缀)并将其编码成神经表示的有效方法 (Ma, &amp; Hovy, 2016)。Figure 1 展现了用CNN提取给定单词的字符级表示。</p>
<figure>
<img src="https://i.loli.net/2019/05/20/5ce23f703124d64378.png" alt="Figure 1: 卷积神经网络用于提取单词的字符级表示。 虚线箭头表示在向CNN输入字符嵌入之前应用了一个dropout层"><figcaption>Figure 1: 卷积神经网络用于提取单词的字符级表示。 虚线箭头表示在向CNN输入字符嵌入之前应用了一个dropout层</figcaption>
</figure>
<p>用CNN计算出每个单词的字符级表示，然后字符级向量表示连接词级向量组成最终的输入向量。</p>
<h2 id="训练与评估">4 训练与评估</h2>
<p><strong>词嵌入。</strong> 常使用斯坦福大学公开的GloVe 嵌入式系统，该系统训练了来自维基百科和网络文本的60亿个单词 (Pennington et al., 2014)。</p>
<p><strong>数据集。</strong> 常使用宾夕法尼亚大学的《华尔街日报》部分 Treebank (PTB) (Marcus et al., 1993)，其中包含45个不同的POS标签。并分为训练集和测试集。而准确度标准采用F1分数。</p>
<table>
<thead>
<tr class="header">
<th>Mocel</th>
<th>Acc.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bi-LSTM (Plank et al., 2016)</td>
<td>97.22</td>
</tr>
<tr class="even">
<td>Feed Forward (Vaswani et a. 2016)</td>
<td>97.4</td>
</tr>
<tr class="odd">
<td>NCRF++ (Yang and Zhang, 2018)</td>
<td>97.49</td>
</tr>
<tr class="even">
<td>LSTM-CNNs-CRF (Ma and Hovy, 2016)</td>
<td>97.55</td>
</tr>
<tr class="odd">
<td>Adversarial Bi-LSTM (Yasunaga et al., 2018)</td>
<td>97.59</td>
</tr>
<tr class="even">
<td>Meta BiLSTM (Bohnet et al., 2018)</td>
<td>97.96</td>
</tr>
</tbody>
</table>
<p>Table 1: 近几年的各种模型的测试结果。</p>
<h2 id="目前与未来研究">5 目前与未来研究</h2>
<p>过去以及目前，很多模型都字符级或词级的词嵌入来改善模型性能，还有一些是通过优化语言模型来助力提高词性标注的准确性。未来，一种可能是会通过预训练的强大语言模型或词嵌入来继续提高词性标注性能；二是提出一种新型的网络模型来产生突破性的成果。</p>
<h2 id="参考">参考</h2>
<ul>
<li>Lafferty, J., McCallum, A., &amp; Pereira, F. (2001). Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</li>
<li>Goller, C., &amp; Kuchler, A. (1996, June). Learning task-dependent distributed representations by backpropagation through structure. In Proceedings of International Conference on Neural Networks (ICNN'96) (Vol. 1, pp. 347-352). IEEE.</li>
<li>Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780.</li>
<li>Cho, K., Van Merriënboer, B., Bahdanau, D., &amp; Bengio, Y. (2014). On the properties of neural machine translation: Encoder-decoder approaches. arXiv preprint arXiv:1409.1259.</li>
<li>Chiu, J. P., &amp; Nichols, E. (2016). Named entity recognition with bidirectional LSTM-CNNs. Transactions of the Association for Computational Linguistics, 4, 357-370.</li>
<li>Ma, X., &amp; Hovy, E. (2016). End-to-end sequence labeling via bi-directional lstm-cnns-crf. arXiv preprint arXiv:1603.01354.</li>
<li>Pennington, J., Socher, R., &amp; Manning, C. (2014). Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532-1543).</li>
<li>Marcus, M., Santorini, B., &amp; Marcinkiewicz, M. A. (1993). Building a large annotated corpus of English: The Penn Treebank.</li>
<li>Plank, B., Søgaard, A., &amp; Goldberg, Y. (2016). Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss. arXiv preprint arXiv:1604.05529.</li>
<li>Vaswani, A., Bisk, Y., Sagae, K., &amp; Musa, R. (2016). Supertagging with lstms. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 232-237).</li>
<li>Yang, J., &amp; Zhang, Y. (2018). Ncrf++: An open-source neural sequence labeling toolkit. arXiv preprint arXiv:1806.05626.</li>
<li>Yasunaga, M., Kasai, J., &amp; Radev, D. (2017). Robust multilingual part-of-speech tagging via adversarial training. arXiv preprint arXiv:1711.04903.</li>
<li>Bohnet, B., McDonald, R., Simoes, G., Andor, D., Pitler, E., &amp; Maynez, J. (2018). Morphosyntactic tagging with a meta-bilstm model over context sensitive token encodings. arXiv preprint arXiv:1805.08237.</li>
</ul>

    
    </div>
    
    <div class="columns is-variable is-1 is-multiline is-mobile">
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/NLP/">#NLP</a></span>
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a></span>
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a></span>
    
    </div>
    
    <!-- 
    <span id="2019/11/23/pos-review/" class="leancloud_visitors" data-flag-title="词性标注的简单综述">
        <em class="post-meta-item-text">阅读量 </em>
        <i class="leancloud-visitors-count">1000000</i>
    </span>
     -->
    
    <div class="go-next columns is-mobile is-multiline article-nav">
        <span class="column is-12-mobile is-half-desktop  article-nav-prev">
            
            <a href="/2019/12/28/raft/">Raft 简述</a>
            
        </span>
        <span class="column is-12-mobile is-half-desktop  article-nav-next">
            
            <a href="/2019/09/25/linux-select/">Linux Select 源码分析</a>
            
        </span>
    </div>
    
</article>



<div class="comments">
    <h3 class="title is-4">Comments</h3>
    
<div id="valine-thread"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script>
    new Valine({
        el: '#valine-thread',
        appId: 'DEXiOMuMN86LKmdUtJYX4FRL-MdYXbMMI',
        appKey: 'tPt6E0GhkwXKEBUacbugDcWb',
        notify: false,
        verify: false,
        avatar: '',
        placeholder: 'Say something...',
        meta: ['nick', 'mail'],
        visitor: true,
        lang: ''
    })
</script>


</div>

    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2020 Black Redscarf&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" href="https://github.com/blackredscarf" target="_blank" rel="noopener">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>
</footer>
    <script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="https://cdn.bootcdn.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/" target="_blank" rel="noopener">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.bootcdn.net/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("en-AU");
</script>


    
    
<script src="https://cdn.bootcdn.net/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [ ['$','$'],['\\(','\\)'] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: false
        }
    });
</script>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        // ...options...
    });
});
</script>

    
    
<script src="https://cdn.bootcdn.net/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="https://cdn.bootcdn.net/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    


<script src="/js/script.js"></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</body>
</html>